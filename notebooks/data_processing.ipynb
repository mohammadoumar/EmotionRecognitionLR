{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20aa00d-c84a-4970-bc99-ffd9f8ed9776",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "640868d0-4cf7-4fb0-bfb3-3ed663372d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import pandas as pd # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d559c8fe-52ba-4a42-9717-128a5767ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "data_dir = os.path.join(parent_dir, \"data_files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460323af-143e-40c3-80d4-6b1548ef27ad",
   "metadata": {},
   "source": [
    "### Read files into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43b20516-1199-4e23-8b1f-25aa930b539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = glob.glob(os.path.join(data_dir, '*.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae7c9947-9c67-4e8b-97f2-ad222677371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "\n",
    "    df = pd.read_excel(file_path)\n",
    "    df['file_name'] = os.path.basename(file_path)\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6870874c-077e-4124-8d8b-1871e1cec4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4f9abe-2e33-4c47-b620-a9fe0be44c62",
   "metadata": {},
   "source": [
    "### Process dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23eef39c-3233-4532-92f3-e6012a7e7f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Annotations'].notna()].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f99ca047-754c-4b70-97d4-84ef9802cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['raw_emotion', 'raw_speaker_id']] = df['Annotations'].str.split('\\n\\n', expand=True, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75b303ef-a42e-432e-ad37-2d5fce310022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_emotion(x):\n",
    "\n",
    "    raw_emotion = x.raw_emotion\n",
    "    try:\n",
    "        emotion = raw_emotion.split(\"\\n\")[1].split(\":\")[1]\n",
    "    except:\n",
    "        emotion = \"no annotation\"\n",
    "\n",
    "    return emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e8316a8-d68c-4ce3-8c17-12b6cf228fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emotion'] = df.apply(lambda x: process_emotion(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b50e5fd-89d6-46dd-8118-e08079e4b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_speaker(x):\n",
    "\n",
    "    raw_speaker_id = x.raw_speaker_id\n",
    "    \n",
    "    try:\n",
    "        if 'SpokenBy:' in raw_speaker_id.split(\"\\n\")[0]:\n",
    "            speaker_id = raw_speaker_id.split(\"\\n\")[0].split(\":\")[1]\n",
    "            \n",
    "        elif 'SpokenBy:' in raw_speaker_id.split(\"\\n\")[1]:            \n",
    "            speaker_id = raw_speaker_id.split(\"\\n\")[1].split(\":\")[1]\n",
    "            \n",
    "        elif 'SpokenBy:' in raw_speaker_id.split(\"\\n\")[2]:            \n",
    "            speaker_id = raw_speaker_id.split(\"\\n\")[2].split(\":\")[1]\n",
    "\n",
    "        return speaker_id\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        speaker_id = \"no annotation\"\n",
    "\n",
    "        return speaker_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6d7fe1d-8966-4457-b5b3-4cb9744483b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['speaker_id'] = df.apply(lambda x: process_speaker(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "851f0a1b-3981-480e-ac18-7a4fb18368b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['index', 'Translated text in Spanish; Castilian', 'Number of words.1', 'Signs with spaces.1', 'Signs without spaces.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "423ea0e0-442b-4842-8ecd-51eb46e6f622",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Source text in English': 'utterance', 'Annotations': 'raw_annotation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fcc3705-31cb-4c6e-8b93-d5be6a12e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Number of words', 'Signs with spaces', 'Signs without spaces'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1935db31-ef7f-49cf-b18e-3f60f1d880ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Page': 'page_nr', 'Panel': 'panel_nr', 'Balloon': 'balloon_nr'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69c4c257-dec0-4c4c-9f42-5fc618372f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['file_name', 'page_nr', 'panel_nr', 'balloon_nr', 'utterance', 'raw_annotation', 'raw_emotion', 'raw_speaker_id', 'emotion', 'speaker_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48b5d2c-c04d-4ce0-94da-48dbfe0284d4",
   "metadata": {},
   "source": [
    "### train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d2f0c4f-8088-4976-a402-ed3ad9b63b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_list = list(df.file_name.unique())\n",
    "num_train = int(len(titles_list) * 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1086a88b-3c1e-4478-97ac-731928e63200",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_titles = random.sample(titles_list, num_train)\n",
    "test_titles = [title for title in titles_list if title not in train_titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b5d5234-c873-4f34-886a-8905a2761039",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['split'] = df['file_name'].apply(lambda x: 'TRAIN' if x in train_titles else ('TEST' if x in test_titles else 'UNKNOWN'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4162c214-de34-4dd1-8a80-b86cd201ca87",
   "metadata": {},
   "source": [
    "#### clean dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1afde234-daa7-4c16-ad5d-b174f4f5fad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_idx = [1093, 26, 1447]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c84dc04-388b-41d0-af0d-f90a8aca27f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.index[wrong_idx]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95a0e8f3-96c8-4dd3-b3ea-1961b6f64b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker = df.iloc[1129]['raw_annotation'].split(\"\\n\\n\")[0].split(\":\")[1]\n",
    "emotion = df.iloc[1129]['raw_annotation'].split(\"\\n\\n\")[1].split(\":\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7fbf023-893b-41d6-ad0f-6bc0cfb9ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1129, 8] = emotion\n",
    "df.iloc[1129, 9] = speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4631f6ad-7ab3-4d2c-b69f-4ca190f513a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker = df.iloc[1411]['raw_annotation'].split(\"\\n\\n\")[0].split(\":\")[1]\n",
    "emotion = df.iloc[1411]['raw_annotation'].split(\"\\n\\n\")[1].split(\":\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bce95e1-b3b1-46c0-a41b-7249283955ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1411, 8] = emotion\n",
    "df.iloc[1411, 9] = speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc1939c1-e37b-4c2b-8919-4fbbff6ffe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.emotion != \"no annotation\"].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1f10831-9350-4fea-a454-6cbb55794af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"comics_data_processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faa0984-9f2f-4ffc-8a66-2c207881942c",
   "metadata": {},
   "source": [
    "### dataframe grouped by titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e2c0948-66e0-4cb3-89fd-d33cb8ff7f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_title = df.groupby('file_name').agg({'utterance': list, 'emotion': list, 'split': set}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c905be1-7332-47ff-9d36-ca172b9bd89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_title_text(x):\n",
    "\n",
    "    list_utterances = x.utterance\n",
    "    full_title_text = ' '.join(list_utterances)\n",
    "\n",
    "    return full_title_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "251b7a71-ca35-4695-ab18-295aae9e8540",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_title['full_title_text'] = df_by_title.apply(lambda x: get_full_title_text(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64f23a35-9765-4383-86f2-442b9d2badab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_title = df_by_title.rename(columns={'utterance': 'utterances_l', 'emotion': 'emotions_l'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3fe2ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_split(x):\n",
    "\n",
    "    return list(x.split)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2dea807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_title['split'] = df_by_title.apply(lambda x: process_split(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21ce65cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_utterance_indices(row):\n",
    "\n",
    "    title_text = row.full_title_text\n",
    "    utterances_l = row.utterances_l\n",
    "\n",
    "    start_indices = []\n",
    "    end_indices = []\n",
    "    \n",
    "    for utterance in utterances_l:\n",
    "        start = title_text.find(utterance)\n",
    "        if start != -1:\n",
    "            # Append the start index and calculate the end index\n",
    "            start_indices.append(start)\n",
    "            end_indices.append(start + len(utterance))\n",
    "        else:\n",
    "            # If substring not found, append -1 to both lists\n",
    "            start_indices.append(-1)\n",
    "            end_indices.append(-1)\n",
    "    \n",
    "    return start_indices, end_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6641a549",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_title['start_indices', 'end_indices'] = df_by_title.apply(lambda row: find_utterance_indices(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "576abc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_title[['start_indices', 'end_indices']] = pd.DataFrame(df_by_title[('start_indices', 'end_indices')].tolist(), index=df_by_title.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d044e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_title.to_csv(\"comics_data_by_title.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f2fa22-35d5-41aa-abf1-5a9987ee0b08",
   "metadata": {},
   "source": [
    "### Prepare prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3fd57164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting Fx\n",
    "# Build questoin\n",
    "# Build answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "608f81e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_fct(instruction=\"\", input=\"\", output=\"\"):\n",
    "    \n",
    "    prompt_d ={\n",
    "            \n",
    "        \"instruction\": f\"\"\"{instruction}\"\"\",\n",
    "        \"input\": f\"\"\"{input}\"\"\",\n",
    "        \"output\": f\"\"\"{output}\"\"\"\n",
    "            \n",
    "        }\n",
    "    \n",
    "    return prompt_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b107f77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_instruction(nr_utterances):\n",
    "\n",
    "    results = json.dumps([\"emotion_class (str)\"] * nr_utterances)\n",
    "\n",
    "    instruction = f\"\"\"### You are an expert in Emotion Analysis. You are given the transcript of a comic book which contains numbered character utterances enclosed by <UT></UT> tags. Your task is to classify each utterance in the comic transcript as on the following emotion classes: \"Anger\" (AN), \"Disgust\" (DI), \"Fear\" (FE), \"Sadness\" (SA), \"Surprise\" (SU) or \"Joy\" (JO). You must return a list of emotion classes, strictly of length {nr_utterances}, in following JSON format: {{\"emotion_class\": [\"emotion_class (str)\", \"emotion_class (str)\" ... \"emotion_class (str)\"]}} where each element \"emotion_class (str)\" is replaced by one of the following abbreviated emotion class labels: \"AN\", \"DI\", \"FE\", \"SA\", \"SU\" or \"JO\". \n",
    "\"\"\"    \n",
    "    return instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1144129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_tagged_text(text, start_indices, end_indices):\n",
    "\n",
    "#     offset = 0\n",
    "\n",
    "#     for i, (start_i, end_i) in enumerate(zip(start_indices, end_indices)):\n",
    "            \n",
    "#         start_tag = \"<UT\" + str(i+1) + \">\"\n",
    "#         end_tag = \"</UT\" + str(i+1) + \">\"\n",
    "        \n",
    "#         start_idx = start_i + offset\n",
    "#         end_idx = end_i + offset\n",
    "\n",
    "#         offset = offset + (len(start_tag)  + len(end_tag))\n",
    "        \n",
    "#         text_r = text[start_idx:end_idx]\n",
    "#         new_text = start_tag + text_r + end_tag\n",
    "#         text = text.replace(text_r, new_text)\n",
    "\n",
    "#         question = f\"\"\"### Here is the comic transcript: {text}\"\"\"\n",
    "\n",
    "#     return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44e9dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tagged_text(utterances_l):\n",
    "\n",
    "    tagged_utterances_l = []\n",
    "\n",
    "    for idx, utterance in enumerate(utterances_l):\n",
    "        \n",
    "        start_tag = \"<UT\" + str(idx+1) + \">\"\n",
    "        end_tag = \"</UT\" + str(idx+1) + \">\"\n",
    "        tagged_utterance = start_tag + utterance + end_tag\n",
    "        tagged_utterances_l.append(tagged_utterance)\n",
    "        \n",
    "    tagged_title_text = ''.join(tagged_utterances_l)\n",
    "    question = f\"\"\"### Here is the comic transcript: {tagged_title_text}\"\"\"\n",
    "\n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "539b6d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_answer(title_emotions):\n",
    "\n",
    "    title_emotions_l = []\n",
    "    emotion_class_labels = [\"Anger\", \"Disgust\", \"Fear\", \"Sadness\", \"Surprise\", \"Joy\"]\n",
    "\n",
    "    for emotions_l in title_emotions:\n",
    "\n",
    "            if emotions_l == 'Neutral':\n",
    "                title_emotions_l.append([emotions_l])\n",
    "            \n",
    "            else:\n",
    "                emotions_l = emotions_l.split(\"-\")\n",
    "               \n",
    "                emotion_annotation_l = []\n",
    "\n",
    "                for idx, emotion_annotation in enumerate(emotions_l):\n",
    "\n",
    "                    if '0' not in emotion_annotation:\n",
    "                 \n",
    "                        #emotion_annotation_l.append(emotion_class_labels[idx])\n",
    "                        emotion_annotation_l.append(emotion_annotation[:-1])\n",
    "                    \n",
    "                title_emotions_l.append(emotion_annotation_l)\n",
    "                \n",
    "\n",
    "    return json.dumps({\"emotion_classes\": title_emotions_l})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd67b57",
   "metadata": {},
   "source": [
    "### Build Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85fd7584",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_by_title[df_by_title.split == 'TRAIN'].reset_index()\n",
    "\n",
    "data_file_train = []\n",
    "\n",
    "for index, _ in df_train.iterrows():\n",
    "    \n",
    "    i = index\n",
    "\n",
    "    instruction = build_instruction(len(df_train.iloc[i].utterances_l))\n",
    "    question = build_tagged_text(df_train.iloc[i].utterances_l)\n",
    "    answer = build_answer(df_train.iloc[i].emotions_l)\n",
    "    \n",
    "    data_file_train.append( formatting_fct(instruction, question, answer) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "181fe00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_file_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f7a42377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': '### You are an expert in Emotion Analysis. You are given the transcript of a comic book which contains numbered character utterances enclosed by <UT></UT> tags. Your task is to classify each utterance in the comic transcript as on the following emotion classes: \"Anger\" (AN), \"Disgust\" (DI), \"Fear\" (FE), \"Sadness\" (SA), \"Surprise\" (SU) or \"Joy\" (JO). You must return a list of emotion classes, strictly of length 34, in following JSON format: {\"emotion_class\": [\"emotion_class (str)\", \"emotion_class (str)\" ... \"emotion_class (str)\"]} where each element \"emotion_class (str)\" is replaced by one of the following abbreviated emotion class labels: \"AN\", \"DI\", \"FE\", \"SA\", \"SU\" or \"JO\". \\n', 'input': '### Here is the comic transcript: <UT1>In Rio de Janeiro my brakes were cut.</UT1><UT2>In Mexico l was slipped psilocybin while fighting a pack of jaguars.</UT2><UT3>And now, in SHANGHAI…</UT3><UT4>< I\\'VE GOT YOU! GO LIMP! > *</UT4><UT5>< THIS DOESN\\'T --MY POLYETHYLENE LINES ARE IMPOSSIBLE TO BREAK! ></UT5><UT6>< BUT NOT IMPOSSIBLE… ></UT6><UT7><… TO CUT. ></UT7><UT8>It\\'s HIM.</UT8><UT9>< I KNOW THE POLICE ARE AFTER ME FOR MY \" SKYSPIDER \" STUNTS. BUT WHY YOU? ></UT9><UT10>Jealousy? Some sick game?</UT10><UT11>If he\\'s HERE, he must have…</UT11><UT12>Dammit. I should have figured it out based on SKYSPIDER\\'S mask…</UT12><UT13>< QIU. HAVE YOU TRAINED ANYONE ELSE LATELY? ></UT13><UT14>< I… YEAH. ></UT14><UT15>< A GUY AROUND YOUR AGE. COULDN\\'T PLACE HIS ACCENT. ></UT15><UT16>< CALLED HIMSELF \"ANTON.\" ></UT16><UT17>He didn\\'t even bother to use a DIFFERENT fake name…</UT17><UT18>… because he wants me to know he\\'s one step ahead of me.</UT18><UT19>Like in DUBLIN.</UT19><UT20>Or METROPOLIS.</UT20><UT21>Or MOROCCO.</UT21><UT22>Where he ended the life of our master Ouahbi once he realized he was training a PSYCHOPATH.</UT22><UT23>I miss my friend.</UT23><UT24>I miss who I thought he was.</UT24><UT25>He haunts me now, like a ghost, as I near the finish line.</UT25><UT26>My mission has always been about saving people, but Anton…</UT26><UT27>… I\\'m afraid one day he might kill me. He has all my skills, but his mind has no distractions, whereas mine…</UT27><UT28>I have FEAR.</UT28><UT29>I\\'m afraid I won\\'t be able to save myself and this mission will end and I\\'ll join my parents in the ground.</UT29><UT30>So I need to visit one more MASTER…</UT30><UT31>… to make my MIND ready.</UT31><UT32>To make me COLD AND TERRIFYING.</UT32><UT33>To make me a creature of the NIGHT.</UT33><UT34>PLEASE, COME IN, MR. WAYNE…</UT34>', 'output': '{\"emotion_classes\": [[\"AN\", \"FE\", \"SU\"], [\"AN\", \"FE\", \"SA\"], [\"AN\", \"FE\", \"SA\"], [\"FE\", \"SA\", \"SU\"], [\"AN\", \"JO\"], [\"JO\"], [\"JO\"], [\"SU\"], [\"AN\", \"SU\"], [\"AN\", \"SU\"], [\"FE\", \"SU\"], [\"AN\", \"DI\", \"SA\", \"SU\"], [\"FE\", \"SA\"], [\"FE\", \"SU\", \"JO\"], [\"Neutral\"], [\"Neutral\"], [\"AN\", \"DI\", \"SU\"], [\"AN\", \"DI\"], [\"AN\", \"DI\"], [\"AN\", \"DI\"], [\"AN\", \"DI\"], [\"AN\", \"DI\", \"SA\"], [\"SA\"], [\"SA\"], [\"FE\", \"SA\"], [\"AN\", \"DI\", \"SA\"], [\"FE\", \"SA\"], [\"FE\"], [\"FE\", \"SA\"], [\"Neutral\"], [\"Neutral\"], [\"Neutral\"], [\"JO\"], [\"JO\"]]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given the transcript of a comic book which contains numbered character utterances enclosed by <UT></UT> tags. Your task is to classify each utterance in the comic transcript as on the following emotion classes: \"Anger\" (AN), \"Disgust\" (DI), \"Fear\" (FE), \"Sadness\" (SA), \"Surprise\" (SU) or \"Joy\" (JO). You must return a list of emotion classes, strictly of length 132, in following JSON format: {\"emotion_class\": [\"emotion_class (str)\", \"emotion_class (str)\" ... \"emotion_class (str)\"]} where each element \"emotion_class (str)\" is replaced by one of the following abbreviated emotion class labels: \"AN\", \"DI\", \"FE\", \"SA\", \"SU\" or \"JO\". \\n', 'input': '### Here is the comic transcript: <UT1>THIS VILE THING ATTACKED THE SMALL BEASTS OF MY SHORES… </UT1><UT2>… IT PUNCHED MY BEAUTIFUL MATILDA… AND NOW IT BEGS FOR LIFE.</UT2><UT3>MY MASTER!</UT3><UT4>PLEASE!</UT4><UT5>BUT I HAVE NOT CHASED THIS MONSTER ALL THIS WAY TO LET IT GROVEL!</UT5><UT6>HEAL MEEE!</UT6><UT7>I HAVE COME TO CONQ--!</UT7><UT8>WHAT--</UT8><UT9>--IS THAT?!</UT9><UT10>NO! NO!</UT10><UT11>NO--  #GKKK…#</UT11><UT12>#CHOMP!</UT12><UT13>BY THE SKIN OF MATILDA!</UT13><UT14>BLACKMANTASAURUS! WHAT KIND OF MONSTER EATS ITS OWN WARRIORS?</UT14><UT15>#MUNCH! MUNCH!</UT15><UT16>#PTOOO!</UT16><UT17>VERY WELL.</UT17><UT18>YOU WANT A FIGHT?</UT18><UT19>YOU GOT ONE!</UT19><UT20>COME ON, BEAST!</UT20><UT21>SHOW YOURSELF!</UT21><UT22>WHY DO YOU HIDE BEHIND YOUR EGGSHELL WALLS?!</UT22><UT23>LET US DO BATTLE!</UT23><UT24>#AARGH! </UT24><UT25>I, THE GREEN TORCH, HAVE BEEN TASKED WITH PROTECTING THIS JUNGLE FROM THE EVILS THAT COME FROM THE STARS.</UT25><UT26>TODAY, I FULFILL THAT DUTY --AND DEFEAT THIS MONSTER, ATROCITAURUS!</UT26><UT27>#AGH!</UT27><UT28>#UKKK…#</UT28><UT29>HOLD ON TO YOUR BUTT!</UT29><UT30>EVER SINCE I FOUND MY TORCH IN DEEP SPACE, I HAVE BEEN LOOKING FOR A WORTHY FOE…</UT30><UT31>… BUT THAT FOE IS NOT YOU!</UT31><UT32>GREEN TORCH, BEWARE… HE IS… COMING…</UT32><UT33>YOU WILL… FAIL…</UT33><UT34>...</UT34><UT35>FLASHRAPTOR-- WHERE\\'S AQUANYX?</UT35><UT36>HE CHASED THE MANTA BEAST AWAY FROM HERE.</UT36><UT37>HIS SCENT\\'S STILL IN THE AIR</UT37><UT38>I BET WE COULD TRACK HIM.</UT38><UT39>YEAH, MAN.</UT39><UT40>LET\\'S GATHER UP THESE TWO AND GO FIND OUR FRIEND…</UT40><UT41>\"… SOMETHING TELLS ME HE NEEDS OUR HELP! \"</UT41><UT42>ALL THIS… CHAOS…</UT42><UT43>… IT\\'S ALL CONNECTED.</UT43><UT44>BATSAUR!</UT44><UT45>I\\'VE GOT A PLAN READY FOR US.</UT45><UT46>THERE IS A GREAT EVIL COMING OUR WAY.</UT46><UT47>WE MUST PREPARE AND FORTIFY.</UT47><UT48>FORTIFY? YOU MEAN--</UT48><UT49>WE WILL TRAVEL THERE, TO THE TOP OF THE GREAT MOUNTAIN, AND SET UP DEFENSES.</UT49><UT50>YOU WANT TO WAIT FOR YOUR DOOM? NO. WE MUST TAKE THE FIGHT TO WHAT THREATENS US, SUPERSAUR!</UT50><UT51>WE DO NOT KNOW HOW STRONG THIS THREAT IS!</UT51><UT52>WE CAN\\'T JUST MARCH IN-THE RISK IS TOO GREAT!</UT52><UT53>BESIDES, WE DON\\'T EVEN KNOW WHERE THIS EVIL IS!</UT53><UT54>WELL, THEN LET\\'S MAKE THEM TELL THE TRUTH.</UT54><UT55>HEY!</UT55><UT56>TELL US, GIGANTA!</UT56><UT57>WHERE IS YOUR MASTER?!</UT57><UT58>THE… CENTER OF THE JUNGLE. WHERE THE TREES DO NOT GROW, AND THE INSECTS DO NOT TREAD. IT CAN ONLY BE VIEWED FROM ABOVE, BUT IT IS BELOW.</UT58><UT59>A DARK MAGIC GUARDS ITS LOCATION FROM THE CREATURES THAT WALK ON THE GROUND.</UT59><UT60>EVEN WITH THE LASSO, YOU SPEAK IN RIDDLES! TELL US WHERE IT IS!</UT60><UT61>IT IS USELESS! HE HAS USED ALL OF US FOR HIS DARK PURPOSE… WHICH IS ALMOST FULFILLED.</UT61><UT62>HE IS COMING…</UT62><UT63>… FOR ALL OF US.</UT63><UT64>BUT HE WILL BE STOPPED. BY ALL OF US.</UT64><UT65>MAYBE HE\\'LL BE STOPPED BY YOU. BUT I WILL NOT BE THERE.</UT65><UT66>WHAT?!</UT66><UT67>HE WILL FIND A WAY… ALWAYS… ALWAYS FINDS A WAY…</UT67><UT68>THAT GREAT EVIL IS SOMEHOW CONNECTED TO THE JOKERZARD.</UT68><UT69>AND IF I HUNT THAT EVIL… CHANCES ARE I WILL FIND HIS MINIONS…</UT69><UT70>… INCLUDING THE ONE THAT KILLED MY…</UT70><UT71>… I MUST GO.</UT71><UT72>THANK YOU, CHILD.</UT72><UT73>YOU ARE LEARNING.</UT73><UT74>SHE SHOULD BE HERE. WITH US.</UT74><UT75>SHE\\'S BEEN THROUGH ENOUGH THAT SHE HAS GROWN A STRONG MIND. SHE SHOULD DECIDE FOR HERSELF.</UT75><UT76>WONDERDON AND I NEED YOUR STRENGTH, BATSAUR. PLEASE…. DO NOT LEAVE US LIKE THIS.</UT76><UT77>YOU PRETEND THAT WE ARE FRIENDS, BUT I DO NOT KNOW EITHER OF YOU.</UT77><UT78>YOU ARE MERELY MORE OBSTACLES ON MY PATH TO REVENGE.</UT78><UT79>AND WHEN YOU GET YOUR REVENGE… WILL YOU BE WHOLE?</UT79><UT80>MORE SO THAN I AM NOW.</UT80><UT81>WHERE WILL YOU GO?</UT81><UT82>GIGANTA SAID, IN ORDER TO FIND THIS EVIL\\'S LOCATION, I HAD TO SEE IT FROM UP HIGH.</UT82><UT83>THIS WILL GET US THERE.</UT83><UT84>COME, CHILD…</UT84><UT85>… LET\\'S GO FIND JOKERZARD!</UT85><UT86>SUPERSAUR, WE MUST MOVE THE PEOPLE TO THE GREAT MOUNTAIN.</UT86><UT87>SOMETHING TELLS ME WE\\'RE RUNNING OUT OF TIME.</UT87><UT88>DEAR MOTHER, THE DINOSAURS HERE BICKER CONSTANTLY. THERE IS DISUNITY. NO ONE TRUSTS EACH OTHER.</UT88><UT89>IT MAKES ME MISS TRIMYSCIRA AND HOW WE COULD GIVE IN TO EACH OTHER COMPLETELY WITH NO FEAR OF BETRAYAL.</UT89><UT90>WE ARE MAKING DEFENSES AND PREPARING FOR THIS UNKNOWN TERROR TO COME. BUT I KNOW IT IS NOT ENOUGH.</UT90><UT91>I MUST RALLY THESE GREAT DINOSAURS TO A HIGHER CAUSE.</UT91><UT92>BUT HOW CAN I, WITH DEATH SO NEAR?</UT92><UT93>HOW CAN I INSPIRE WITH ONLY A BONE SWORD AND SHIELD?</UT93><UT94>< MY SON.> *</UT94><UT95>< HELLO, FATHER. ></UT95><UT96>< FATHER… AM I WEAK? ></UT96><UT97>< WEAK? WHATEVER DO YOU MEAN? ></UT97><UT98>< SHOULD I HAVE LEFT WITH BATSAUR?</UT98><UT99>IS MY JOB TO HUNT ALL EVIL? EVERYWHERE? ></UT99><UT100>< I… I DON\\'T KNOW, MY BOY. ></UT100><UT101><… BUT ONE THING I DO KNOW… IS HOW GOOD YOU ARE. INSIDE AND OUT. ></UT101><UT102><THEY NEED TO SEE THAT. THE WHOLE WORLD NEEDS TO SEE.</UT102><UT103>AND… YOU CAN\\'T CHANGE THE WORLD IF YOU STAY HERE. ></UT103><UT104>< BUT DAD… YOU AND MOM ARE HERE. I CAN\\'T LEAVE YOU. I HAVE TO KEEP YOU SAFE.></UT104><UT105><YOU MUSTN\\'T WORRY YOURSELF OVER US TOO MUCH. WE CAN TAKE CARE OF OURSELVES. YOU\\'VE TAUGHT US HOW STRONG WE ARE.></UT105><UT106>< I KNOW YOU\\'LL DO THE RIGHT THING.></UT106><UT107>WHAT MADNESS IS THIS-- BEING THRASHED BY SOME WORTHLESS EGG?!</UT107><UT108>#WHOM! WHOM! WHOM!</UT108><UT109>DO YOUR WORST!</UT109><UT110>FINISH IT ALREADY!</UT110><UT111>HANG ON, AQUANYX!</UT111><UT112>MY BROTHERS!</UT112><UT113>COME ON, I\\'LL GET YOU OUTTA HERE WHILE TORCH GIVES US COVER.</UT113><UT114>OH NO! WHY DID YOU BRING JOKERZARD AND REVERSE-SLASH WITH YOU?</UT114><UT115>WE DIDN\\'T WANT THEM TO CAUSE ANY MORE TROUB-</UT115><UT116>#AIEEE!</UT116><UT117>NO, MY MASTER, PLEA--</UT117><UT118>#MUNCH! MUNCH!</UT118><UT119>#GLUPS!</UT119><UT120>THE TIME HAS COME TO HATCH.</UT120><UT121>STOP GAWKING AND GET US OUT OF HERE, BROTHERS!</UT121><UT122>LET\\'S GO!</UT122><UT123>#GRRRPP! </UT123><UT124>GRRRPP!</UT124><UT125>FUEL FROM THE WEAKLINGS ON THIS PITIFUL EARTH…</UT125><UT126>THE LIFE ENERGY FROM MY OWN WARRIORS…</UT126><UT127>..HAS FINALLY LED TO MY TRUE FORM!</UT127><UT128>I KNOW THE BEINGS OF THIS WORLD ARE TRYING TO RISE AGAINST ME…</UT128><UT129>… BUT I WILL CRUSH THEM IN DUE TIME!</UT129><UT130>FOR MY FIRST TASK...</UT130><UT131>… I MUST REMOVE THIS WORLD OF THEIR GODS!</UT131><UT132>TRIMYSCIRA! DARKYLOSEID IS COMING FOR YOU!</UT132>', 'output': '{\"emotion_classes\": [[\"AN\"], [\"AN\"], [\"FE\"], [\"FE\"], [\"FE\", \"SA\"], [\"SA\"], [\"AN\"], [\"SU\"], [\"SU\"], [\"FE\", \"SU\"], [\"FE\"], [\"AN\"], [\"SU\"], [\"AN\"], [\"JO\"], [\"AN\"], [\"AN\"], [\"AN\"], [\"AN\"], [\"JO\"], [\"JO\"], [\"AN\"], [\"AN\"], [\"FE\", \"SU\"], [\"AN\"], [\"AN\"], [\"FE\"], [\"FE\", \"SU\"], [\"AN\", \"JO\"], [\"AN\"], [\"SA\"], [\"FE\"], [\"JO\"], [\"Neutral\"], [\"SU\"], [\"FE\"], [\"SU\"], [\"JO\"], [\"SU\"], [\"SA\", \"SU\"], [\"SU\"], [\"FE\", \"SA\"], [\"SU\"], [\"SU\"], [\"JO\"], [\"FE\"], [\"FE\"], [\"AN\"], [\"FE\"], [\"AN\", \"SU\"], [\"FE\"], [\"FE\"], [\"FE\", \"SA\"], [\"SU\"], [\"SU\"], [\"AN\"], [\"AN\"], [\"FE\"], [\"FE\"], [\"AN\"], [\"AN\", \"FE\", \"SU\"], [\"FE\", \"SA\"], [\"FE\", \"SA\"], [\"AN\"], [\"AN\"], [\"SU\"], [\"FE\"], [\"AN\", \"SU\"], [\"AN\"], [\"AN\", \"SA\"], [\"AN\"], [\"JO\"], [\"JO\"], [\"FE\"], [\"JO\"], [\"FE\", \"SA\"], [\"AN\", \"DI\", \"SU\"], [\"AN\", \"DI\"], [\"FE\"], [\"AN\", \"DI\"], [\"FE\", \"SU\"], [\"AN\"], [\"JO\"], [\"JO\"], [\"AN\"], [\"FE\"], [\"SA\"], [\"SA\"], [\"SA\"], [\"FE\", \"SA\"], [\"FE\"], [\"FE\"], [\"SA\"], [\"JO\"], [\"JO\"], [\"SA\"], [\"SU\"], [\"SA\"], [\"SU\"], [\"FE\", \"SU\"], [\"JO\"], [\"JO\"], [\"SA\"], [\"SA\", \"SU\"], [\"SA\", \"JO\"], [\"SA\", \"JO\"], [\"AN\", \"SU\"], [\"AN\", \"JO\"], [\"AN\"], [\"AN\"], [\"FE\"], [\"SU\", \"JO\"], [\"FE\"], [\"SU\"], [\"FE\"], [\"FE\", \"SU\"], [\"FE\"], [\"JO\"], [\"JO\"], [\"JO\"], [\"AN\", \"FE\"], [\"FE\"], [\"AN\"], [\"AN\"], [\"DI\", \"JO\"], [\"JO\"], [\"AN\", \"JO\"], [\"AN\"], [\"AN\"], [\"AN\"], [\"AN\", \"JO\"], [\"AN\"]]}'}\n",
      "{'instruction': '### You are an expert in Emotion Analysis. You are given the transcript of a comic book which contains numbered character utterances enclosed by <UT></UT> tags. Your task is to classify each utterance in the comic transcript as on the following emotion classes: \"Anger\" (AN), \"Disgust\" (DI), \"Fear\" (FE), \"Sadness\" (SA), \"Surprise\" (SU) or \"Joy\" (JO). You must return a list of emotion classes, strictly of length 183, in following JSON format: {\"emotion_class\": [\"emotion_class (str)\", \"emotion_class (str)\" ... \"emotion_class (str)\"]} where each element \"emotion_class (str)\" is replaced by one of the following abbreviated emotion class labels: \"AN\", \"DI\", \"FE\", \"SA\", \"SU\" or \"JO\". \\n', 'input': '### Here is the comic transcript: <UT1>\" Tell me another story, Momma. \"</UT1><UT2>\" What kind of story, Eleanor? \"</UT2><UT3>\" One about John.</UT3><UT4>\" Tell me how he became the Guardian. \"</UT4><UT5>\" Well, your brother doesn\\'t like to talk about it much. You know that.</UT5><UT6>\" Nuh-uh. \"</UT6><UT7>\" A marine is a kind of soldier.</UT7><UT8>\" Before long, John and a lot of other soldiers got sent across the ocean to fight a war. \"</UT8><UT9>No!</UT9><UT10>Kyle!</UT10><UT11>\" And while he was there… just like every war that ever was…</UT11><UT12>\"… something terrible happened. \"</UT12><UT13>#YAAARRRRRGGH!</UT13><UT14>\" Bad enough that John did something he wasn\\'t in the habit of doing back then. \"</UT14><UT15>KYLE!</UT15><UT16>Jason, it\\'s too late!</UT16><UT17>\" He prayed. \"</UT17><UT18>John.</UT18><UT19>John, We need you.</UT19><UT20>\" He prayed for the strength to save the people who needed him.</UT20><UT21>\" And in a flash of light, where your brother stood… \"</UT21><UT22>… there stood an invincible knight, his eyes blazing with the light of heaven.</UT22><UT23>That\\'s how your brother became a superhero, sweetie. Earth\\'s first and greatest.</UT23><UT24>After the Battle of Oa, he founded a team of Lanterns called the Watchtower to protect Earth while he flew all over the Multiverse.</UT24><UT25>Isn\\'t that nice?</UT25><UT26>#Uh-huh.</UT26><UT27>Enough, all right? I\\'m working on it. Can I stop hearing about it, please?</UT27><UT28>You\\'re only hearing about it because you\\'re sneaking around back there instead of working.</UT28><UT29>Nobody\\'s sneaking! Can\\'t I take a minute to look at my girls?</UT29><UT30>One day, when he\\'d done what he set out to do, he took off his ring, and passed it on.</UT30><UT31>He became an architect, like he\\'d always wanted.</UT31><UT32>And now we all live here together in the house he built for us, and he\\'s finally putting up a fence to keep the rabbits out of my flowers.</UT32><UT33>Just pretend I\\'m not here, all right?</UT33><UT34>#Hmm.</UT34><UT35>What about the war, Momma? What if the…</UT35><UT36>… th-the…</UT36><UT37>JOHN.</UT37><UT38>JOHN.</UT38><UT39>WE NEED YOU.</UT39><UT40>Rayner? Is that you?</UT40><UT41>THEY\\'VE FOUND HER, JOHN.</UT41><UT42>MANY OF US HAVE FALLEN.</UT42><UT43>THE BRIGHT REVENANT IS WITH THEM.</UT43><UT44>What, Momma?</UT44><UT45>Did something happen again?</UT45><UT46>I-it\\'s nothing, sweetie. Why don\\'t you practice your reading for a bit?</UT46><UT47>I need to talk to your brother.</UT47><UT48>You told me you formed the Watchtower so they wouldn\\'t need you anymore. That you were done fighting.</UT48><UT49>It\\'s nothing to worry about. The Corps just needs a hand with--</UT49><UT50>Don\\'t talk to me like I\\'m stupid, John. She said, \" They found her. \"</UT50><UT51>You gave me back the daughter I buried. The same age she was when I lost her, and she hasn\\'t aged a day since then. </UT51><UT52>I know a miracle like that has to be paid back someday.</UT52><UT53>Tell me the truth, John…</UT53><UT54>… is that day today?</UT54><UT55>They\\'re called the Radiant Dead.</UT55><UT56>They\\'re the ones that killed the Old Guardians.</UT56><UT57>If they\\'d killed the Central Battery like they meant to, there wouldn\\'t be a Corps anymore… probably nothing else, either.</UT57><UT58>So I took the battery from Oa, and I hid it…</UT58><UT59>… in the shape of my baby sister.</UT59><UT60>It really is still her, Mom. My memory of her, anyway. She\\'s just… more than she used to be.</UT60><UT61>Don\\'t worry. I\\'ll fix this.</UT61><UT62>I\\'ll never forget what you did for your sister.</UT62><UT63>But swear to me you\\'ll come back, too.</UT63><UT64>I will. I\\'ll come back.</UT64><UT65>You\\'ll never have to bury either of us again.</UT65><UT66>I\\'ve gotta leave for a bit, kiddo. But I won\\'t be long.</UT66><UT67>Take care of your momma, yeah?</UT67><UT68>Okay.</UT68><UT69>And keep practicing your reading. You know We love hearing you read.</UT69><UT70>I know.</UT70><UT71>I\\'ll be right back.</UT71><UT72>And I\\'ll finish that fence.</UT72><UT73>Where\\'s John going, Momma?</UT73><UT74>He\\'s going to do what he does, sweetie.</UT74><UT75>The things no one else can do.</UT75><UT76>\" What do you mean, \\'no one else\\'?\\' Cause John was a soldier? \"</UT76><UT77>\" Some people think so. His way of never quitting… his mind for strategy, the way he leads people.</UT77><UT78>\" But no, that\\'s not why.</UT78><UT79>\" John\\'s special because he\\'s a builder.</UT79><UT80>\" His mind has always pushed against the limitations that were set on him.</UT80><UT81>\" Limitations of resources, or time… even the rules of three-dimensional space.</UT81><UT82>\" With his mind, his will, and the power he\\'s been given, he can do anything.</UT82><UT83>\"… is that he was looking for the ring before he knew it existed.</UT83><UT84>\" My boy\\'s been the Guardian since the day he was born. \"</UT84><UT85>\" But he\\'s not limited anymore.</UT85><UT86>\" What makes him special, even among the other Lanterns…</UT86><UT87>The Guardian is with us!</UT87><UT88>\" And whether any of us like it or not… ”</UT88><UT89>\"… there are some threats only he can face. \"</UT89><UT90>John!</UT90><UT91>Sit-rep, Natasha.</UT91><UT92>Does this situation not speak for itself?</UT92><UT93>An hour ago, we had 2,300 Lanterns! We\\'re down to barely a thousand!</UT93><UT94>932!</UT94><UT95>You should\\'ve called me earlier.</UT95><UT96>You\\'re retired!</UT96><UT97>It\\'s okay. We\\'re gonna get them all back.</UT97><UT98>If the big one gets any closer to the Battery, it\\'s gonna--</UT98><UT99>Oh god. It\\'s happening.</UT99><UT100>Everybody fall back!</UT100><UT101>The BRIGHT REVENANT is awake!</UT101><UT102>It\\'s headed for Earth!</UT102><UT103>It\\'s after the Battery.</UT103><UT104>I\\'ve got him.</UT104><UT105>You\\'ve…? What, alone?!</UT105><UT106>John, it\\'ll kill you!</UT106><UT107>You\\'re not wrong to be afraid, kid. But you\\'re wrong to let them see it.</UT107><UT108>We\\'re Lanterns.</UT108><UT109>Let our enemies fear us.</UT109><UT110>I know what you are.</UT110><UT111>I know how old you are and how strong.</UT111><UT112>I know you\\'ve killed the greatest heroes and gods of a thousand worlds.</UT112><UT113>But this isn\\'t their home you\\'re threatening now.</UT113><UT114>It\\'s mine.</UT114><UT115>The Guardian!</UT115><UT116>All hail the Guardian!</UT116><UT117>Hail John Stewart!</UT117><UT118>\" Your brother was the greatest of all time. He always will be.</UT118><UT119>\" But he did his time as a superhero. \"</UT119><UT120>Like all the heroes in the old stories, his works of war are done. Now he\\'s doing his works of peace.</UT120><UT121>Will the monsters come back, Momma?</UT121><UT122>Will they try to take me away again?</UT122><UT123>No, sweetie.</UT123><UT124>With your brother John around…</UT124><UT125>\"… we\\'ll never be apart again. \"</UT125><UT126>IT\\'S BEEN THREE YEARS. THREE YEARS OF RESEARCH. THREE YEARS OF TRACKING DOWN LEGENDS AND MYTHS. ALL LEADING HERE…</UT126><UT127>… THE TEMPLE OF LIFE.</UT127><UT128>AND THE TWO MEN WITH ME? ABOUT AS TRUSTWORTHY AS SOMEONE WITH THE LAST NAME LUTHOR.</UT128><UT129>BUT LIKE LUTHOR, THEY\\'D DO ANYTHING FOR CASH.</UT129><UT130>NOW?</UT130><UT131>WHICH IS GREAT, BECAUSE I DIDN\\'T FEEL LIKE CARRYING THE BAGS.</UT131><UT132>BAGS I\\'M SURE THEY THINK THEY\\'LL FILL WITH TREASURE AFTER THEY GET RID OF ME.</UT132><UT133>BOY, DID THEY GET THAT WRONG.</UT133><UT134>MY NAME IS KENDRA SAUNDERS, SOMETIMES KNOWN AS HAWKGIRL. AND I\\'M NOT DYING TODAY.</UT134><UT135>TODAY IS THE FIRST DAY OF THE REST OF MY LIFE.</UT135><UT136>I\\'M SURE THESE GOONS\\'LL BE OKAY. I MEAN, IT\\'S NOT LIKE THE JUNGLE IS TEEMING WITH POISONOUS ANIMALS, BUGS, SNAKES… OH WAIT.</UT136><UT137>BUT THEY MIGHT FARE BETTER WITH THOSE THAN WHAT\\'S IN HERE.</UT137><UT138>IT\\'S CALLED THE TEMPLE OF LIFE, BUT IT\\'S REALLY ANYTHING BUT.</UT138><UT139>EXACTLY WHAT I NEED.</UT139><UT140>I KNOW. SOUNDS STRANGE. BUT SO IS MY LIFE… OR LIVES, AS IT WERE.</UT140><UT141>I\\'VE ACTUALLY BEEN REINCARNATED HUNDREDS OF TIMES. AND WHAT\\'S EVEN WILDER, I REMEMBER EACH OF THOSE LIVES.</UT141><UT142>SOUNDS FUN, RIGHT? TO KEEP COMING BACK?</UT142><UT143>KNOWING IF I LANDED IN A PIT LIKE THESE GUYS BELOW ME, I\\'D JUST APPEAR IN A NEW BODY, READY TO TRY AGAIN.</UT143><UT144>LIKE SOME SORT OF MYSTICAL VIDEO GAME WITH INFINITE LIVES.</UT144><UT145>BUT WHAT I THOUGHT WAS A BLESSING TURNED OUT TO BE A CURSE. A BURDEN.</UT145><UT146>I REALIZED THAT NO MATTER WHAT I DID, IT WAS SOMETHING I HAD DONE BEFORE. A LIFE OF PERPETUAL SAMENESS.</UT146><UT147>I WAS NO LONGER UNIQUE. I WASN\\'T EVEN A PERSON. NOT REALLY. I WAS… A VESSEL WAITING TO BE EMPTIED AND FILLED UP AGAIN AND AGAIN…</UT147><UT148>IT\\'S LIKE DA VINCI SAID, \" I THOUGHT I WAS LEARNING TO LIVE. I WAS ONLY LEARNING TO DIE. \"</UT148><UT149>BUT TODAY THAT CHANGES.</UT149><UT150>TODAY I GET MY LIFE BACK. I GET MY MORTALITY.</UT150><UT151>AND NOTHING… IS GOING TO STOP ME!</UT151><UT152>NOT EVEN ANCIENT DEATH TRAPS.</UT152><UT153>THERE IT IS. THE VASE OF MORTALITY.</UT153><UT154>LEGEND HAS IT THAT AN ANCIENT GOD-KING CREATED THE WORLD AND MADE EVERYTHING IN IT IN HIS IMAGE-IMMORTAL. NOTHING DIED, AND BECAUSE OF IT, NOTHING LIVED.</UT154><UT155>THE BEAUTY OF THE WORLD THAT WAS ONCE SO VIBRANT, OVER TIME, TURNED DULL.</UT155><UT156>THE GOD\\'S SON AND DAUGHTER TOLD THE GOD-KING HE WAS WRONG TO MAKE THE WORLD LIKE THEM, AND THE KING AGREED.</UT156><UT157>HE CRIED A RIVER OF TEARS, WHICH FILLED THE EARTH. AND WHEN THE TEARS RECEDED, THE ANIMALS AND PLANTS HAD REGAINED THEIR LUSTER. THEY KNEW THAT THEIR LIVES WOULD END, AND THEREFORE, THEY HAD BETTER GET TO LIVING THEM.</UT157><UT158>NO MORE PAST. NO MORE FUTURE, NO MORE \" DESTINY. \"</UT158><UT159>JUST TODAY.</UT159><UT160>JUST THE CHANCE TO MAKE MY OWN DECISIONS. TO CHOOSE MY OWN RELATIONSHIPS. TO SOMEDAY PASS AWAY KNOWING THAT I WAS UNIQUE TO MYSELF. A SNOWFLAKE NEVER TO BE SEEN AGAIN.</UT160><UT161>I WAS SPECIAL.</UT161><UT162>YOU DO THIS, KENDRA, THAT\\'S IT. YOU\\'VE ONLY GOT ONE MORE SHOT AT LIFE.</UT162><UT163>#### IT!</UT163><UT164>I FEEL… FINE.</UT164><UT165>MAYBE IT WAS JUST A STUPID MYTH--</UT165><UT166>#ACK! </UT166><UT167>#AHHHHH… AHHHH… AHH… #HUFF#</UT167><UT168>IT\\'S GONE. THE MEMORIES. THE LIVES.</UT168><UT169>I\\'M ALIVE. THE DREAM OF MY FUTURE MY OWN. NO MORE REINCARNATION. JUST THE LIFE AHEAD OF ME AND WHAT I CHOOSE TO MAKE OF IT.</UT169><UT170>#ACK!</UT170><UT171>ARE YOU KIDDING ME?! THIS IS IT? THIS IS HOW IT ENDS? NOW?!</UT171><UT172>AND NO MORE… NO MORE COMING BACK. THIS IS HOW I DIE?</UT172><UT173>SO WHY DO I FEEL SO ALIVE?</UT173><UT174>#HAH!</UT174><UT175>MY HEART IS BEATING FASTER THAN IT EVER HAS.</UT175><UT176>THIS IS WHAT IT FELT LIKE BEFORE I KNEW ABOUT THE PAST.</UT176><UT177>THIS IS WHAT IT FEELS LIKE TO KNOW THE FUTURE IS YOUR OWN.</UT177><UT178>NOT ONE THAT IS HANDED TO YOU…</UT178><UT179>… BUT ONE THAT YOU FIGHT FOR.</UT179><UT180>THAT\\'S TRUE LIVING.</UT180><UT181>THAT\\'S THE DREAM OF MY HEART.</UT181><UT182>#HAHAHAHHAHAHAHAHA!</UT182><UT183>#HAHAHAHHAHAHAHAHA!</UT183>', 'output': '{\"emotion_classes\": [[\"JO\"], [\"SU\"], [\"JO\"], [\"JO\"], [\"SA\", \"SU\"], [\"SU\", \"JO\"], [\"SA\", \"SU\"], [\"SA\"], [\"FE\", \"SU\"], [\"FE\", \"SU\"], [\"SA\"], [\"FE\", \"SA\"], [\"FE\"], [\"FE\", \"SU\"], [\"FE\", \"SU\"], [\"FE\"], [\"SU\"], [\"FE\", \"SU\"], [\"FE\", \"SU\"], [\"SU\"], [\"SU\"], [\"SU\"], [\"SU\", \"JO\"], [\"JO\"], [\"JO\"], [\"SU\", \"JO\"], [\"AN\"], [\"JO\"], [\"SU\", \"JO\"], [\"SU\"], [\"JO\"], [\"JO\"], [\"JO\"], [\"SU\", \"JO\"], [\"SU\"], [\"Neutral\"], [\"Neutral\"], [\"FE\"], [\"FE\"], [\"SU\"], [\"FE\", \"SU\"], [\"SA\"], [\"FE\", \"SA\"], [\"SU\"], [\"FE\"], [\"SA\", \"SU\"], [\"SA\"], [\"AN\", \"SU\"], [\"SU\"], [\"AN\", \"SU\"], [\"FE\", \"SU\"], [\"FE\", \"SA\"], [\"AN\", \"FE\"], [\"FE\"], [\"AN\"], [\"AN\", \"SA\"], [\"AN\", \"FE\"], [\"FE\"], [\"FE\"], [\"JO\"], [\"FE\"], [\"SU\", \"JO\"], [\"FE\"], [\"FE\"], [\"SA\"], [\"JO\"], [\"JO\"], [\"SU\", \"JO\"], [\"JO\"], [\"JO\"], [\"JO\"], [\"JO\"], [\"SU\"], [\"FE\", \"JO\"], [\"FE\", \"JO\"], [\"SU\"], [\"SU\", \"JO\"], [\"SU\"], [\"SU\", \"JO\"], [\"SU\", \"JO\"], [\"SU\", \"JO\"], [\"JO\"], [\"SU\", \"JO\"], [\"JO\"], [\"JO\"], [\"SU\", \"JO\"], [\"SU\", \"JO\"], [\"FE\", \"SU\"], [\"FE\"], [\"SU\"], [\"SU\"], [\"FE\", \"SU\"], [\"FE\", \"SA\", \"SU\"], [\"SU\"], [\"SA\", \"SU\"], [\"SA\"], [\"SU\"], [\"FE\"], [\"FE\", \"SU\"], [\"FE\", \"SU\"], [\"SU\", \"JO\"], [\"FE\", \"SU\"], [\"FE\", \"SU\"], [\"FE\"], [\"SU\"], [\"FE\"], [\"SU\"], [\"JO\"], [\"AN\"], [\"AN\"], [\"AN\"], [\"AN\", \"SA\"], [\"AN\", \"DI\"], [\"AN\"], [\"JO\"], [\"JO\"], [\"JO\"], [\"JO\"], [\"SA\", \"JO\"], [\"JO\"], [\"FE\"], [\"FE\"], [\"SU\", \"JO\"], [\"JO\"], [\"JO\"], [\"SU\"], [\"SU\"], [\"JO\"], [\"FE\", \"SA\"], [\"SU\"], [\"JO\"], [\"FE\", \"JO\"], [\"SA\"], [\"AN\"], [\"AN\"], [\"FE\"], [\"FE\"], [\"FE\", \"SU\"], [\"JO\"], [\"SA\"], [\"SA\", \"SU\"], [\"SA\", \"JO\"], [\"SA\"], [\"SA\"], [\"SA\", \"SU\"], [\"SA\", \"SU\"], [\"SA\", \"SU\"], [\"SA\"], [\"JO\"], [\"JO\"], [\"AN\"], [\"AN\"], [\"JO\"], [\"SA\"], [\"SA\"], [\"FE\", \"SU\"], [\"SA\", \"SU\"], [\"JO\"], [\"JO\"], [\"FE\", \"JO\"], [\"SU\"], [\"FE\"], [\"AN\"], [\"SU\", \"JO\"], [\"FE\", \"SA\", \"SU\"], [\"FE\", \"SU\"], [\"FE\"], [\"SU\"], [\"SU\", \"JO\"], [\"FE\", \"SU\"], [\"AN\", \"FE\", \"SU\"], [\"AN\", \"FE\", \"SU\"], [\"SU\"], [\"AN\"], [\"SU\"], [\"SU\", \"JO\"], [\"SU\", \"JO\"], [\"SU\"], [\"JO\"], [\"JO\"], [\"JO\"], [\"JO\"], [\"JO\"]]}'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(data_file_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "91becc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_by_title[df_by_title.split == 'TEST'].reset_index()\n",
    "\n",
    "data_file_test = []\n",
    "\n",
    "for index, _ in df_test.iterrows():\n",
    "    \n",
    "    i = index\n",
    "\n",
    "    instruction = build_instruction(len(df_test.iloc[i].utterances_l))\n",
    "    question = build_tagged_text(df_test.iloc[i].utterances_l)\n",
    "    answer = build_answer(df_test.iloc[i].emotions_l)\n",
    "    \n",
    "    data_file_test.append( formatting_fct(instruction, question, answer) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb35781",
   "metadata": {},
   "source": [
    "### Create and save JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "01306b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(os.getcwd(), \"../datasets/comics_train.json\")\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    \n",
    "    json.dump(data_file_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9b6f5885",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(os.getcwd(), \"../datasets/comics_test.json\")\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    \n",
    "    json.dump(data_file_test, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b15a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
