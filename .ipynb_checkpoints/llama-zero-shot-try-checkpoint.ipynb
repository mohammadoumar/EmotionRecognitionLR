{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oHFCsV0z-Jw"
   },
   "source": [
    "# 003829 Zero Shot LLama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lr7rB3szzhtx"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "giM74oK1rRIH",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %cd ..\n",
    "# %rm -rf LLaMA-Factory\n",
    "# !git clone https://github.com/hiyouga/LLaMA-Factory.git\n",
    "# %cd LLaMA-Factory\n",
    "# %ls\n",
    "# !pip install -e .[torch,bitsandbytes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip uninstall -y pydantic\n",
    "# !pip install pydantic==1.10.9 # \n",
    "\n",
    "# !pip uninstall -y gradio\n",
    "# !pip install gradio==3.48.0\n",
    "\n",
    "# !pip uninstall -y bitsandbytes\n",
    "# !pip install --upgrade bitsandbytes\n",
    "\n",
    "# !pip install tqdm\n",
    "# !pip install ipywidgets\n",
    "# !pip install scikit-learn\n",
    "\n",
    "# Restart kernel afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from llamafactory.chat import ChatModel\n",
    "from llamafactory.extras.misc import torch_gc\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:    \n",
    "    assert torch.cuda.is_available() is True\n",
    "    \n",
    "except AssertionError:\n",
    "    \n",
    "    print(\"Please set up a GPU before using LLaMA Factory...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TeYs5Lz-QJYk"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Utilisateurs/umushtaq'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"unsloth/llama-3-8b-Instruct-bnb-4bit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd /content/LLaMA-Factory/\n",
    "\n",
    "args = dict(\n",
    "  model_name_or_path=base_model, # use bnb-4bit-quantized Llama-3-8B-Instruct model\n",
    "  #adapter_name_or_path=output_dir,            # load the saved LoRA adapters\n",
    "  template=\"llama3\",                     # same to the one in training\n",
    "  finetuning_type=\"lora\",                  # same to the one in training\n",
    "  quantization_bit=4,                    # load 4-bit quantized model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:2108] 2024-06-06 09:05:13,197 >> loading file tokenizer.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-06 09:05:13,200 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-06 09:05:13,201 >> loading file special_tokens_map.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-06 09:05:13,203 >> loading file tokenizer_config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/tokenizer_config.json\n",
      "[WARNING|logging.py:314] 2024-06-06 09:05:13,586 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/06/2024 09:05:13 - INFO - llamafactory.data.template - Replace eos token: <|eot_id|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Utilisateurs/umushtaq/.conda/envs/llama-factory-notebook/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "[INFO|configuration_utils.py:733] 2024-06-06 09:05:13,709 >> loading configuration file config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/config.json\n",
      "[INFO|configuration_utils.py:796] 2024-06-06 09:05:13,712 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"_load_in_4bit\": true,\n",
      "    \"_load_in_8bit\": false,\n",
      "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "    \"bnb_4bit_quant_type\": \"nf4\",\n",
      "    \"bnb_4bit_use_double_quant\": true,\n",
      "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "    \"llm_int8_has_fp16_weight\": false,\n",
      "    \"llm_int8_skip_modules\": null,\n",
      "    \"llm_int8_threshold\": 6.0,\n",
      "    \"load_in_4bit\": true,\n",
      "    \"load_in_8bit\": false,\n",
      "    \"quant_method\": \"bitsandbytes\"\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/06/2024 09:05:13 - INFO - llamafactory.model.utils.quantization - Loading ?-bit BITSANDBYTES-quantized model.\n",
      "06/06/2024 09:05:13 - INFO - llamafactory.model.patcher - Using KV cache for faster generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING|quantization_config.py:393] 2024-06-06 09:05:14,367 >> Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "[INFO|modeling_utils.py:3474] 2024-06-06 09:05:14,393 >> loading weights file model.safetensors from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/model.safetensors\n",
      "[INFO|modeling_utils.py:1519] 2024-06-06 09:05:14,457 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:962] 2024-06-06 09:05:14,463 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:4280] 2024-06-06 09:05:18,513 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4288] 2024-06-06 09:05:18,515 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at unsloth/llama-3-8b-Instruct-bnb-4bit.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:917] 2024-06-06 09:05:18,643 >> loading configuration file generation_config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/generation_config.json\n",
      "[INFO|configuration_utils.py:962] 2024-06-06 09:05:18,646 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128009\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/06/2024 09:05:18 - INFO - llamafactory.model.utils.attention - Using torch SDPA for faster training and inference.\n",
      "06/06/2024 09:05:18 - INFO - llamafactory.model.adapter - Adapter is not found at evaluation, load the base model.\n",
      "06/06/2024 09:05:18 - INFO - llamafactory.model.loader - all params: 8030261248\n"
     ]
    }
   ],
   "source": [
    "model = ChatModel(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"### You are an expert in Emotion Analysis. You are given the transcription of a comics page which contains utterances by characters enclosed by <text></text> tags. Your task is to identify the emotion of each text utterance from the following emotion classes: Anger, Disgust, Fear, Joy, Neutral, Sadness, Surprise. You must return a list of emotion classes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### You are an expert in Emotion Analysis. You are given the transcription of a comics page which contains utterances by characters enclosed by <text></text> tags. Your task is to identify the emotion of each text utterance from the following emotion classes: Anger, Disgust, Fear, Joy, Neutral, Sadness, Surprise. You must return a list of emotion classes.\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_page_6 = \"\"\"\n",
    "PAGE 6:\n",
    " PANEL 1:\n",
    "  <text>LEAVING THE SULKING ROBIN, WE RETURN ONCE MORE\n",
    "  ΤΟ\n",
    "  JUSTICE LEAGUE HEAD-QUARTERS…</text>\n",
    " PANEL 2:\n",
    "  <text>I FOUND THE MALLED FLASH NORTH OF GOTHAM CITY--</text>\n",
    "  <text>THE READINGS ON THE THANAGARIAN METABOLIC REVIVER ARE TURNING POSITIVE! THE SPEEDSTER'S GONNA MAKE IT!</text>\n",
    " PANEL 3:\n",
    "  <text>JUST THEN…</text>\n",
    "  <text>OHH: WHAT'S ALL THE COMMOTION--?</text>\n",
    "  <text>FLASH IS GOING-RUNNING --WILD!</text>\n",
    " PANEL 4:\n",
    "  <text>NEWLY ARRIVED BLACK CANARY AND GREEN ARROW WATCH IN STUNNED AMAZEMENT AS…</text>\n",
    "  <text>CAUGHT UP TO HIM--UNNH--HE'S CONKED OUT AGAIN!</text>\n",
    "  <text>FLASH STARTED TO SAY SOMETHING--BUT SO FAST, IT CAME OUT GARBLED:</text>\n",
    " PANEL 5:\n",
    "  <text>MY SUPER-HEARING CAUGHT ENOUGH TO HEAR, FLASH MUTTER ALIEN--MONSTER--NEW CARTHAGE!</text>\n",
    " PANEL 6:\n",
    "  <text>NEW\n",
    "  CARTHAGE.? THAT'S WHERE--\n",
    "  HUDSON --AND UNIVERSITY PICK\n",
    "  15-</text>\n",
    " PANEL 7:\n",
    "  <text>( ROBIN ) GRAYSON!<text></text>\n",
    "  <text>IT'S AQUAMAN ON THE ALARM--USING THE SPECIAL EMERGENCY CALL FOR BATMAN AND GREEN ARROW!</text>\n",
    "  <text>THAT MEANS A SPLIT-UP!</text>\n",
    "  <text>BATMAN --ARROW --RESPOND TO AQUAMAN'S CALL: THE REST OF THE TEAM WILL TAKE OFF ON A MONSTER-HUNT AROUND NEW CARTHAGE!</text>\n",
    "  <text>GUESS HE GOT OVER HIS MAD!</text>\n",
    "  <text>I'LL REMAIN HERE WITH FLASH IN CASE HE REVIVES AGAIN!</text> \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_page_5 = \"\"\"PAGE 5:\n",
    " PANEL 1:\n",
    "  <text>AN EMERGENCY SIGNAL CALLS FOR A SUPER-SPEED RESPONSE…</text>\n",
    "  <text>GREEN LANTERN--WHAT HAPPENED? LOOKS LIKE A TORNADO HIT YOU!</text>\n",
    "  <text>YEAH… A TORNADO… IN THE FORM OF A KID --A SWEET, INNOCENT, LOVABLE\n",
    "  KID!</text>\n",
    " PANEL 2:\n",
    "  <text>\" AFTER ROBIN AND I WRAPPED UP A CASE NEAR HERE, I DECIDED TO TAKE A SOLO SIDE-TRIP TO CHECK UP ON SLAUGHTER SWAMP WHEN… \"</text>\n",
    "  <text>\" AS I SWOOPED DOWN TO HELP HIM, HE TURNED ON ME WITH A RAGING SNARL… \"</text>\n",
    "  <text>THAT OVERGROWN KID SEEMS LOST--FRANTICALLY TRYING TO SMASH HIS WAY OUT…</text>\n",
    "  <text>I TELE-SENSE YOU CAN BRING TEPPY TO ME!</text>\n",
    "  =\n",
    "  <text>WITH THAT, HE ATTACKED ME--WITH SURPRISING, STUPENDOUS STRENGTH… \"</text>\n",
    " PANEL 3:\n",
    "  <text>WHEN I CAME TO, ROBIN WAS HERE--BUT MY POWER RING WAS GONE!</text>\n",
    "  <text>SHOULDN'T BE HARD TO TRACK DOWN YOUR GO BACK ATTACKER!</text>\n",
    "  <text>THAT'S WHY I SIGNALLED YOU!</text>\n",
    "  <text>BUT I ADVISE YOU TO TO HEAD-QUARTERS AND RECU-PERATE!</text>\n",
    "  <text>USE MY ROBIN-CLIPPER TO GET THERE, GLiI'M STICKING WITH THE JSA!</text>\n",
    " PANEL 4:\n",
    "  <text>HMM… I SUPPOSE SO, ROBIN--SINCE YOU'RE HERE! YOU MAY AS WELL JOIN US, FILL IN FOR BATMAN--</text>\n",
    "  <text>YOU FORGET, CHAIRMAN HAWKMAN --I'VE BEEN ACCEPTED AS A FULL-FLEDGED JSA MEMBER!</text>\n",
    "  <text>MAN, WHAT A PATRONIZING ATTITUDE! GENERATION GAP STRIKES AGAIN!</text>\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_page_7 = \"\"\"\n",
    "PAGE 7:\n",
    " PANEL 1:\n",
    "  <text>NEARING THE COUNTRY-SIDE SURROUNDING HUDSON UNIVERSITY…\n",
    "  DOWN BELOW--DICK GRAYSON--\n",
    "  --IN ROBIN-ACTION!\n",
    "  R</text>\n",
    " PANEL 2:\n",
    "  <text>AFTER MAKING CONTACT…</text>\n",
    "  <text>WHILE ON A CASE *, I HEARD RANGER RADIO-REPORTS OF A MARAUDING MONSTER --SO, I PULLED OUT MY CYCLE AND HEADED THIS WAY!</text>\n",
    "  <text>WHERE WAS THE MONSTER'S LAST-REPORTED SIGHTING?</text>\n",
    " <text> * AS DETAILED IN THE AUGUST BATMAN --\" VENGEANCE FOR A COP! \"</text>\n",
    " PANEL 3:\n",
    "  <text>OVER THAT HILL-RISE ABOUT 20 MILES!</text>\n",
    "  <text>MIGHT AS WELL STASH MY BIKE AND HITCH ALONG WITH YOU!</text>\n",
    " PANEL 4:\n",
    "  <text>THEN AS IS SO FREQUENTLY DUPLICATED ON THE TWIN-EARTHS…</text>\n",
    "  <text>WELL… LONG AS BATMAN ISN'T HERE, YOU MIGHT HELP OUT A LITTLE--</text>\n",
    "  <text>AND THOUGH UNSPOKEN, THE ROBIN-ANGER IS PRECISELY THE SAME!</text>\n",
    " PANEL 5:\n",
    "  <text>WHEWE LOOK AT THAT DESTRUCTION--TREES SCATTERED LIKE MATCHSTICKS!</text>\n",
    "  <text>HEY, WHAT'S MY POWER RING ZEROING IN ON?</text>\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_combined_pages = \"\"\"\n",
    "PAGE 5:\n",
    " PANEL 1:\n",
    "  <text>AN EMERGENCY SIGNAL CALLS FOR A SUPER-SPEED RESPONSE…</text>\n",
    "  <text>GREEN LANTERN--WHAT HAPPENED? LOOKS LIKE A TORNADO HIT YOU!</text>\n",
    "  <text>YEAH… A TORNADO… IN THE FORM OF A KID --A SWEET, INNOCENT, LOVABLE\n",
    "  KID!</text>\n",
    " PANEL 2:\n",
    "  <text>\" AFTER ROBIN AND I WRAPPED UP A CASE NEAR HERE, I DECIDED TO TAKE A SOLO SIDE-TRIP TO CHECK UP ON SLAUGHTER SWAMP WHEN… \"</text>\n",
    "  <text>\" AS I SWOOPED DOWN TO HELP HIM, HE TURNED ON ME WITH A RAGING SNARL… \"</text>\n",
    "  <text>THAT OVERGROWN KID SEEMS LOST--FRANTICALLY TRYING TO SMASH HIS WAY OUT…</text>\n",
    "  <text>I TELE-SENSE YOU CAN BRING TEPPY TO ME!</text>\n",
    "  =\n",
    "  <text>WITH THAT, HE ATTACKED ME--WITH SURPRISING, STUPENDOUS STRENGTH… \"</text>\n",
    " PANEL 3:\n",
    "  <text>WHEN I CAME TO, ROBIN WAS HERE--BUT MY POWER RING WAS GONE!</text>\n",
    "  <text>SHOULDN'T BE HARD TO TRACK DOWN YOUR GO BACK ATTACKER!</text>\n",
    "  <text>THAT'S WHY I SIGNALLED YOU!</text>\n",
    "  <text>BUT I ADVISE YOU TO TO HEAD-QUARTERS AND RECU-PERATE!</text>\n",
    "  <text>USE MY ROBIN-CLIPPER TO GET THERE, GLiI'M STICKING WITH THE JSA!</text>\n",
    " PANEL 4:\n",
    "  <text>HMM… I SUPPOSE SO, ROBIN--SINCE YOU'RE HERE! YOU MAY AS WELL JOIN US, FILL IN FOR BATMAN--</text>\n",
    "  <text>YOU FORGET, CHAIRMAN HAWKMAN --I'VE BEEN ACCEPTED AS A FULL-FLEDGED JSA MEMBER!</text>\n",
    "  <text>MAN, WHAT A PATRONIZING ATTITUDE! GENERATION GAP STRIKES AGAIN!</text>\n",
    "\n",
    "\n",
    "PAGE 6:\n",
    " PANEL 1:\n",
    "  <text>LEAVING THE SULKING ROBIN, WE RETURN ONCE MORE\n",
    "  ΤΟ\n",
    "  JUSTICE LEAGUE HEAD-QUARTERS…</text>\n",
    " PANEL 2:\n",
    "  <text>I FOUND THE MALLED FLASH NORTH OF GOTHAM CITY--</text>\n",
    "  <text>THE READINGS ON THE THANAGARIAN METABOLIC REVIVER ARE TURNING POSITIVE! THE SPEEDSTER'S GONNA MAKE IT!</text>\n",
    " PANEL 3:\n",
    "  <text>JUST THEN…</text>\n",
    "  <text>OHH: WHAT'S ALL THE COMMOTION--?</text>\n",
    "  <text>FLASH IS GOING-RUNNING --WILD!</text>\n",
    " PANEL 4:\n",
    "  <text>NEWLY ARRIVED BLACK CANARY AND GREEN ARROW WATCH IN STUNNED AMAZEMENT AS…</text>\n",
    "  <text>CAUGHT UP TO HIM--UNNH--HE'S CONKED OUT AGAIN!</text>\n",
    "  <text>FLASH STARTED TO SAY SOMETHING--BUT SO FAST, IT CAME OUT GARBLED:</text>\n",
    " PANEL 5:\n",
    "  <text>MY SUPER-HEARING CAUGHT ENOUGH TO HEAR, FLASH MUTTER ALIEN--MONSTER--NEW CARTHAGE!</text>\n",
    " PANEL 6:\n",
    "  <text>NEW\n",
    "  CARTHAGE.? THAT'S WHERE--\n",
    "  HUDSON --AND UNIVERSITY PICK\n",
    "  15-</text>\n",
    " PANEL 7:\n",
    "  <text>( ROBIN ) GRAYSON!<text></text>\n",
    "  <text>IT'S AQUAMAN ON THE ALARM--USING THE SPECIAL EMERGENCY CALL FOR BATMAN AND GREEN ARROW!</text>\n",
    "  <text>THAT MEANS A SPLIT-UP!</text>\n",
    "  <text>BATMAN --ARROW --RESPOND TO AQUAMAN'S CALL: THE REST OF THE TEAM WILL TAKE OFF ON A MONSTER-HUNT AROUND NEW CARTHAGE!</text>\n",
    "  <text>GUESS HE GOT OVER HIS MAD!</text>\n",
    "  <text>I'LL REMAIN HERE WITH FLASH IN CASE HE REVIVES AGAIN!</text>\n",
    "\n",
    "  PAGE 7:\n",
    " PANEL 1:\n",
    "  <text>NEARING THE COUNTRY-SIDE SURROUNDING HUDSON UNIVERSITY…\n",
    "  DOWN BELOW--DICK GRAYSON--\n",
    "  --IN ROBIN-ACTION!\n",
    "  R</text>\n",
    " PANEL 2:\n",
    "  <text>AFTER MAKING CONTACT…</text>\n",
    "  <text>WHILE ON A CASE *, I HEARD RANGER RADIO-REPORTS OF A MARAUDING MONSTER --SO, I PULLED OUT MY CYCLE AND HEADED THIS WAY!</text>\n",
    "  <text>WHERE WAS THE MONSTER'S LAST-REPORTED SIGHTING?</text>\n",
    " <text> * AS DETAILED IN THE AUGUST BATMAN --\" VENGEANCE FOR A COP! \"</text>\n",
    " PANEL 3:\n",
    "  <text>OVER THAT HILL-RISE ABOUT 20 MILES!</text>\n",
    "  <text>MIGHT AS WELL STASH MY BIKE AND HITCH ALONG WITH YOU!</text>\n",
    " PANEL 4:\n",
    "  <text>THEN AS IS SO FREQUENTLY DUPLICATED ON THE TWIN-EARTHS…</text>\n",
    "  <text>WELL… LONG AS BATMAN ISN'T HERE, YOU MIGHT HELP OUT A LITTLE--</text>\n",
    "  <text>AND THOUGH UNSPOKEN, THE ROBIN-ANGER IS PRECISELY THE SAME!</text>\n",
    " PANEL 5:\n",
    "  <text>WHEWE LOOK AT THAT DESTRUCTION--TREES SCATTERED LIKE MATCHSTICKS!</text>\n",
    "  <text>HEY, WHAT'S MY POWER RING ZEROING IN ON?</text>\n",
    "\n",
    "  PAGE 8:\n",
    " PANEL 1:\n",
    "  <text>IT'S TUNED IN ON A STRANGE FORCE--WEIRD VIBES --LIKE A LINK OR A BOND!</text>\n",
    "  <text>SEEMS TO BE CHANNELED INTO--EARTH-TWO!</text>\n",
    "  мей\n",
    "  <text>OH, NO! NOT AGAIN! ANOTHER SUPER-MENACE THAT SIMULTANEOUSLY THREATENS BOTH OUR EARTHS!</text>\n",
    "  <text>YOU BETTER CONTACT THE JUSTICE SOCIETY THROUGH YOUR RING, GL:</text>\n",
    " PANEL 2:\n",
    "  <text>COMMUNICATION IS ESTABLISHED BETWEEN THE TWO JUSTICE GROUPS AND…</text>\n",
    "  <text>WE WERE JUST ON OUR WAY TO FIGHT OUR MENACE!</text>\n",
    "  <text>IT'D BE SCIENTIFICALLY MORE SOUND FOR YOUR SUPERMAN, ATOM, AND FLASH TO COME HERE TO HANDLE OUR MONSTER--\n",
    "  --WHILE OUR GL, HAWKMAN AND ROBIN JOIN YOUR HAWKMAN AND ROBIN IN GOING AFTER THE BOY-MENACE!</text>\n",
    "  <text>PLAYING A HUNCH, ATOM --OR A THEORY?</text>\n",
    "  <text>MY RING SHOULD BE ABLE TO HANDLE THE CROSS-OVER--PROVIDED EVERYONE ADDS HIS WILL POWER TO MY OWN</text>\n",
    " PANEL 3:\n",
    "  <text>THE BODY-WRENCHING EXPERIENCE OF CROSSING THE IN-BETWEEN IS MATCHED BY THE COM-BINED DETERMINED WILL OF TEN HEROES…</text>\n",
    "\n",
    "  \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\"\\nUser:\" + instruction + input_combined_pages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nUser:### You are an expert in Emotion Analysis. You are given the transcription of a comics page which contains utterances by characters enclosed by <text></text> tags. Your task is to identify the emotion of each text utterance from the following emotion classes: Anger, Disgust, Fear, Joy, Neutral, Sadness, Surprise. You must return a list of emotion classes.\\n\\nPAGE 5:\\n PANEL 1:\\n  <text>AN EMERGENCY SIGNAL CALLS FOR A SUPER-SPEED RESPONSE…</text>\\n  <text>GREEN LANTERN--WHAT HAPPENED? LOOKS LIKE A TORNADO HIT YOU!</text>\\n  <text>YEAH… A TORNADO… IN THE FORM OF A KID --A SWEET, INNOCENT, LOVABLE\\n  KID!</text>\\n PANEL 2:\\n  <text>\" AFTER ROBIN AND I WRAPPED UP A CASE NEAR HERE, I DECIDED TO TAKE A SOLO SIDE-TRIP TO CHECK UP ON SLAUGHTER SWAMP WHEN… \"</text>\\n  <text>\" AS I SWOOPED DOWN TO HELP HIM, HE TURNED ON ME WITH A RAGING SNARL… \"</text>\\n  <text>THAT OVERGROWN KID SEEMS LOST--FRANTICALLY TRYING TO SMASH HIS WAY OUT…</text>\\n  <text>I TELE-SENSE YOU CAN BRING TEPPY TO ME!</text>\\n  =\\n  <text>WITH THAT, HE ATTACKED ME--WITH SURPRISING, STUPENDOUS STRENGTH… \"</text>\\n PANEL 3:\\n  <text>WHEN I CAME TO, ROBIN WAS HERE--BUT MY POWER RING WAS GONE!</text>\\n  <text>SHOULDN\\'T BE HARD TO TRACK DOWN YOUR GO BACK ATTACKER!</text>\\n  <text>THAT\\'S WHY I SIGNALLED YOU!</text>\\n  <text>BUT I ADVISE YOU TO TO HEAD-QUARTERS AND RECU-PERATE!</text>\\n  <text>USE MY ROBIN-CLIPPER TO GET THERE, GLiI\\'M STICKING WITH THE JSA!</text>\\n PANEL 4:\\n  <text>HMM… I SUPPOSE SO, ROBIN--SINCE YOU\\'RE HERE! YOU MAY AS WELL JOIN US, FILL IN FOR BATMAN--</text>\\n  <text>YOU FORGET, CHAIRMAN HAWKMAN --I\\'VE BEEN ACCEPTED AS A FULL-FLEDGED JSA MEMBER!</text>\\n  <text>MAN, WHAT A PATRONIZING ATTITUDE! GENERATION GAP STRIKES AGAIN!</text>\\n\\n\\nPAGE 6:\\n PANEL 1:\\n  <text>LEAVING THE SULKING ROBIN, WE RETURN ONCE MORE\\n  ΤΟ\\n  JUSTICE LEAGUE HEAD-QUARTERS…</text>\\n PANEL 2:\\n  <text>I FOUND THE MALLED FLASH NORTH OF GOTHAM CITY--</text>\\n  <text>THE READINGS ON THE THANAGARIAN METABOLIC REVIVER ARE TURNING POSITIVE! THE SPEEDSTER\\'S GONNA MAKE IT!</text>\\n PANEL 3:\\n  <text>JUST THEN…</text>\\n  <text>OHH: WHAT\\'S ALL THE COMMOTION--?</text>\\n  <text>FLASH IS GOING-RUNNING --WILD!</text>\\n PANEL 4:\\n  <text>NEWLY ARRIVED BLACK CANARY AND GREEN ARROW WATCH IN STUNNED AMAZEMENT AS…</text>\\n  <text>CAUGHT UP TO HIM--UNNH--HE\\'S CONKED OUT AGAIN!</text>\\n  <text>FLASH STARTED TO SAY SOMETHING--BUT SO FAST, IT CAME OUT GARBLED:</text>\\n PANEL 5:\\n  <text>MY SUPER-HEARING CAUGHT ENOUGH TO HEAR, FLASH MUTTER ALIEN--MONSTER--NEW CARTHAGE!</text>\\n PANEL 6:\\n  <text>NEW\\n  CARTHAGE.? THAT\\'S WHERE--\\n  HUDSON --AND UNIVERSITY PICK\\n  15-</text>\\n PANEL 7:\\n  <text>( ROBIN ) GRAYSON!<text></text>\\n  <text>IT\\'S AQUAMAN ON THE ALARM--USING THE SPECIAL EMERGENCY CALL FOR BATMAN AND GREEN ARROW!</text>\\n  <text>THAT MEANS A SPLIT-UP!</text>\\n  <text>BATMAN --ARROW --RESPOND TO AQUAMAN\\'S CALL: THE REST OF THE TEAM WILL TAKE OFF ON A MONSTER-HUNT AROUND NEW CARTHAGE!</text>\\n  <text>GUESS HE GOT OVER HIS MAD!</text>\\n  <text>I\\'LL REMAIN HERE WITH FLASH IN CASE HE REVIVES AGAIN!</text>\\n\\n  PAGE 7:\\n PANEL 1:\\n  <text>NEARING THE COUNTRY-SIDE SURROUNDING HUDSON UNIVERSITY…\\n  DOWN BELOW--DICK GRAYSON--\\n  --IN ROBIN-ACTION!\\n  R</text>\\n PANEL 2:\\n  <text>AFTER MAKING CONTACT…</text>\\n  <text>WHILE ON A CASE *, I HEARD RANGER RADIO-REPORTS OF A MARAUDING MONSTER --SO, I PULLED OUT MY CYCLE AND HEADED THIS WAY!</text>\\n  <text>WHERE WAS THE MONSTER\\'S LAST-REPORTED SIGHTING?</text>\\n <text> * AS DETAILED IN THE AUGUST BATMAN --\" VENGEANCE FOR A COP! \"</text>\\n PANEL 3:\\n  <text>OVER THAT HILL-RISE ABOUT 20 MILES!</text>\\n  <text>MIGHT AS WELL STASH MY BIKE AND HITCH ALONG WITH YOU!</text>\\n PANEL 4:\\n  <text>THEN AS IS SO FREQUENTLY DUPLICATED ON THE TWIN-EARTHS…</text>\\n  <text>WELL… LONG AS BATMAN ISN\\'T HERE, YOU MIGHT HELP OUT A LITTLE--</text>\\n  <text>AND THOUGH UNSPOKEN, THE ROBIN-ANGER IS PRECISELY THE SAME!</text>\\n PANEL 5:\\n  <text>WHEWE LOOK AT THAT DESTRUCTION--TREES SCATTERED LIKE MATCHSTICKS!</text>\\n  <text>HEY, WHAT\\'S MY POWER RING ZEROING IN ON?</text>\\n\\n  PAGE 8:\\n PANEL 1:\\n  <text>IT\\'S TUNED IN ON A STRANGE FORCE--WEIRD VIBES --LIKE A LINK OR A BOND!</text>\\n  <text>SEEMS TO BE CHANNELED INTO--EARTH-TWO!</text>\\n  мей\\n  <text>OH, NO! NOT AGAIN! ANOTHER SUPER-MENACE THAT SIMULTANEOUSLY THREATENS BOTH OUR EARTHS!</text>\\n  <text>YOU BETTER CONTACT THE JUSTICE SOCIETY THROUGH YOUR RING, GL:</text>\\n PANEL 2:\\n  <text>COMMUNICATION IS ESTABLISHED BETWEEN THE TWO JUSTICE GROUPS AND…</text>\\n  <text>WE WERE JUST ON OUR WAY TO FIGHT OUR MENACE!</text>\\n  <text>IT\\'D BE SCIENTIFICALLY MORE SOUND FOR YOUR SUPERMAN, ATOM, AND FLASH TO COME HERE TO HANDLE OUR MONSTER--\\n  --WHILE OUR GL, HAWKMAN AND ROBIN JOIN YOUR HAWKMAN AND ROBIN IN GOING AFTER THE BOY-MENACE!</text>\\n  <text>PLAYING A HUNCH, ATOM --OR A THEORY?</text>\\n  <text>MY RING SHOULD BE ABLE TO HANDLE THE CROSS-OVER--PROVIDED EVERYONE ADDS HIS WILL POWER TO MY OWN</text>\\n PANEL 3:\\n  <text>THE BODY-WRENCHING EXPERIENCE OF CROSSING THE IN-BETWEEN IS MATCHED BY THE COM-BINED DETERMINED WILL OF TEN HEROES…</text>\\n\\n  \\n\\n']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = []\n",
    "\n",
    "for prompt in prompts:\n",
    "\n",
    "    messages = []\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    response = \"\"\n",
    "    \n",
    "    for new_text in model.stream_chat(messages):\n",
    "        #print(new_text, end=\"\", flush=True)\n",
    "        response += new_text\n",
    "        #print()\n",
    "    test_predictions.append({\"role\": \"assistant\", \"content\": response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'assistant',\n",
       "  'content': 'After analyzing the transcription of the comics page, I\\'ve identified the emotions expressed by each character in the given emotion classes: Anger, Disgust, Fear, Joy, Neutral, Sadness, and Surprise. Here is the list of emotions:\\n\\n1. \"AN EMERGENCY SIGNAL CALLS FOR A SUPER-SPEED RESPONSE…\"\\n\\t* Neutral\\n2. \"GREEN LANTERN--WHAT HAPPENED? LOOKS LIKE A TORNADO HIT YOU!\"\\n\\t* Neutral\\n3. \"YEAH… A TORNADO… IN THE FORM OF A KID --A SWEET, INNOCENT, LOVABLE KID!\"\\n\\t* Joy\\n4. \"AFTER ROBIN AND I WRAPPED UP A CASE NEAR HERE, I DECIDED TO TAKE A SOLO SIDE-TRIP TO CHECK UP ON SLAUGHTER SWAMP WHEN…\"\\n\\t* Neutral\\n5. \"AS I SWOOPED DOWN TO HELP HIM, HE TURNED ON ME WITH A RAGING SNARL…\"\\n\\t* Anger\\n6. \"THAT OVERGROWN KID SEEMS LOST--FRANTICALLY TRYING TO SMASH HIS WAY OUT…\"\\n\\t* Fear\\n7. \"I TELE-SENSE YOU CAN BRING TEPPY TO ME!\"\\n\\t* Neutral\\n8. \"WITH THAT, HE ATTACKED ME--WITH SURPRISING, STUPENDOUS STRENGTH…\"\\n\\t* Surprise\\n9. \"WHEN I CAME TO, ROBIN WAS HERE--BUT MY POWER RING WAS GONE!\"\\n\\t* Anger\\n10. \"SHOULDN\\'T BE HARD TO TRACK DOWN YOUR GO BACK ATTACKER!\"\\n\\t* Neutral\\n11. \"THAT\\'S WHY I SIGNALLED YOU!\"\\n\\t* Neutral\\n12. \"BUT I ADVISE YOU TO TO HEAD-QUARTERS AND RECU-PERATE!\"\\n\\t* Neutral\\n13. \"USE MY ROBIN-CLIPPER TO GET THERE, GLI\\'M STICKING WITH THE JSA!\"\\n\\t* Neutral\\n14. \"HMM… I SUPPOSE SO, ROBIN--SINCE YOU\\'RE HERE! YOU MAY AS WELL JOIN US, FILL IN FOR BATMAN--\"\\n\\t* Neutral\\n15. \"YOU FORGET, CHAIRMAN HAWKMAN --I\\'VE BEEN ACCEPTED AS A FULL-FLEDGED JSA MEMBER!\"\\n\\t* Joy\\n16. \"MAN, WHAT A PATRONIZING ATTITUDE! GENERATION GAP STRIKES AGAIN!\"\\n\\t* Disgust\\n17. \"LEAVING THE SULKING ROBIN, WE RETURN ONCE MORE ΤΟ JUSTICE LEAGUE HEAD-QUARTERS…\"\\n\\t* Neutral\\n18. \"I FOUND THE MALLED FLASH NORTH OF GOTHAM CITY--\"\\n\\t* Neutral\\n19. \"THE READINGS ON THE THANAGARIAN METABOLIC REVIVER ARE TURNING POSITIVE! THE SPEEDSTER\\'S GONNA MAKE IT!\"\\n\\t* Joy\\n20. \"JUST THEN…\"\\n\\t* Neutral\\n21. \"OHH: WHAT\\'S ALL THE COMMOTION--?\"\\n\\t* Surprise\\n22. \"FLASH IS GOING-RUNNING --WILD!\"\\n\\t* Surprise\\n23. \"NEWLY ARRIVED BLACK CANARY AND GREEN ARROW WATCH IN STUNNED AMAZEMENT AS…\"\\n\\t* Surprise\\n24. \"CAUGHT UP TO HIM--UNNH--HE\\'S CONKED OUT AGAIN!\"\\n\\t* Surprise\\n25. \"FLASH STARTED TO SAY SOMETHING--BUT SO FAST, IT CAME OUT GARBLED:\"\\n\\t* Surprise\\n26. \"MY SUPER-HEARING CAUGHT ENOUGH TO HEAR, FLASH MUTTER ALIEN--MONSTER--NEW CARTHAGE!\"\\n\\t* Surprise\\n27. \"NEW CARTHAGE.? THAT\\'S WHERE--\"\\n\\t* Neutral\\n28. \"HUDSON --AND UNIVERSITY PICK 15-\"\\n\\t* Neutral\\n29. \"( ROBIN ) GRAYSON!\"\\n\\t* Joy\\n30. \"IT\\'S AQUAMAN ON THE ALARM--USING THE SPECIAL EMERGENCY CALL FOR BATMAN AND GREEN ARROW!\"\\n\\t* Neutral\\n31. \"THAT MEANS A SPLIT-UP!\"\\n\\t* Neutral\\n32. \"BATMAN --ARROW --RESPOND TO AQUAMAN\\'S CALL: THE REST OF THE TEAM WILL TAKE OFF ON A MONSTER-HUNT AROUND NEW CARTHAGE!\"\\n\\t* Neutral\\n33. \"GUESS HE GOT OVER HIS MAD!\"\\n\\t* Neutral\\n34. \"I\\'LL REMAIN HERE WITH FLASH IN CASE HE REVIVES AGAIN!\"\\n\\t* Neutral\\n35. \"NEARING THE COUNTRY-SIDE SURROUNDING HUDSON UNIVERSITY…\"\\n\\t* Neutral\\n36. \"DOWN BELOW--DICK GRAYSON--\"\\n\\t* Neutral\\n37. \"R\"\\n\\t* Neutral\\n38. \"A'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"After analyzing the transcription of the comics page, I've identified the emotions expressed by each character in the given emotion classes: Anger, Disgust, Fear, Joy, Neutral, Sadness, and Surprise. Here is the list of emotions:\",\n",
       " '',\n",
       " '1. \"AN EMERGENCY SIGNAL CALLS FOR A SUPER-SPEED RESPONSE…\"',\n",
       " '\\t* Neutral',\n",
       " '2. \"GREEN LANTERN--WHAT HAPPENED? LOOKS LIKE A TORNADO HIT YOU!\"',\n",
       " '\\t* Neutral',\n",
       " '3. \"YEAH… A TORNADO… IN THE FORM OF A KID --A SWEET, INNOCENT, LOVABLE KID!\"',\n",
       " '\\t* Joy',\n",
       " '4. \"AFTER ROBIN AND I WRAPPED UP A CASE NEAR HERE, I DECIDED TO TAKE A SOLO SIDE-TRIP TO CHECK UP ON SLAUGHTER SWAMP WHEN…\"',\n",
       " '\\t* Neutral',\n",
       " '5. \"AS I SWOOPED DOWN TO HELP HIM, HE TURNED ON ME WITH A RAGING SNARL…\"',\n",
       " '\\t* Anger',\n",
       " '6. \"THAT OVERGROWN KID SEEMS LOST--FRANTICALLY TRYING TO SMASH HIS WAY OUT…\"',\n",
       " '\\t* Fear',\n",
       " '7. \"I TELE-SENSE YOU CAN BRING TEPPY TO ME!\"',\n",
       " '\\t* Neutral',\n",
       " '8. \"WITH THAT, HE ATTACKED ME--WITH SURPRISING, STUPENDOUS STRENGTH…\"',\n",
       " '\\t* Surprise',\n",
       " '9. \"WHEN I CAME TO, ROBIN WAS HERE--BUT MY POWER RING WAS GONE!\"',\n",
       " '\\t* Anger',\n",
       " '10. \"SHOULDN\\'T BE HARD TO TRACK DOWN YOUR GO BACK ATTACKER!\"',\n",
       " '\\t* Neutral',\n",
       " '11. \"THAT\\'S WHY I SIGNALLED YOU!\"',\n",
       " '\\t* Neutral',\n",
       " '12. \"BUT I ADVISE YOU TO TO HEAD-QUARTERS AND RECU-PERATE!\"',\n",
       " '\\t* Neutral',\n",
       " '13. \"USE MY ROBIN-CLIPPER TO GET THERE, GLI\\'M STICKING WITH THE JSA!\"',\n",
       " '\\t* Neutral',\n",
       " '14. \"HMM… I SUPPOSE SO, ROBIN--SINCE YOU\\'RE HERE! YOU MAY AS WELL JOIN US, FILL IN FOR BATMAN--\"',\n",
       " '\\t* Neutral',\n",
       " '15. \"YOU FORGET, CHAIRMAN HAWKMAN --I\\'VE BEEN ACCEPTED AS A FULL-FLEDGED JSA MEMBER!\"',\n",
       " '\\t* Joy',\n",
       " '16. \"MAN, WHAT A PATRONIZING ATTITUDE! GENERATION GAP STRIKES AGAIN!\"',\n",
       " '\\t* Disgust',\n",
       " '17. \"LEAVING THE SULKING ROBIN, WE RETURN ONCE MORE ΤΟ JUSTICE LEAGUE HEAD-QUARTERS…\"',\n",
       " '\\t* Neutral',\n",
       " '18. \"I FOUND THE MALLED FLASH NORTH OF GOTHAM CITY--\"',\n",
       " '\\t* Neutral',\n",
       " '19. \"THE READINGS ON THE THANAGARIAN METABOLIC REVIVER ARE TURNING POSITIVE! THE SPEEDSTER\\'S GONNA MAKE IT!\"',\n",
       " '\\t* Joy',\n",
       " '20. \"JUST THEN…\"',\n",
       " '\\t* Neutral',\n",
       " '21. \"OHH: WHAT\\'S ALL THE COMMOTION--?\"',\n",
       " '\\t* Surprise',\n",
       " '22. \"FLASH IS GOING-RUNNING --WILD!\"',\n",
       " '\\t* Surprise',\n",
       " '23. \"NEWLY ARRIVED BLACK CANARY AND GREEN ARROW WATCH IN STUNNED AMAZEMENT AS…\"',\n",
       " '\\t* Surprise',\n",
       " '24. \"CAUGHT UP TO HIM--UNNH--HE\\'S CONKED OUT AGAIN!\"',\n",
       " '\\t* Surprise',\n",
       " '25. \"FLASH STARTED TO SAY SOMETHING--BUT SO FAST, IT CAME OUT GARBLED:\"',\n",
       " '\\t* Surprise',\n",
       " '26. \"MY SUPER-HEARING CAUGHT ENOUGH TO HEAR, FLASH MUTTER ALIEN--MONSTER--NEW CARTHAGE!\"',\n",
       " '\\t* Surprise',\n",
       " '27. \"NEW CARTHAGE.? THAT\\'S WHERE--\"',\n",
       " '\\t* Neutral',\n",
       " '28. \"HUDSON --AND UNIVERSITY PICK 15-\"',\n",
       " '\\t* Neutral',\n",
       " '29. \"( ROBIN ) GRAYSON!\"',\n",
       " '\\t* Joy',\n",
       " '30. \"IT\\'S AQUAMAN ON THE ALARM--USING THE SPECIAL EMERGENCY CALL FOR BATMAN AND GREEN ARROW!\"',\n",
       " '\\t* Neutral',\n",
       " '31. \"THAT MEANS A SPLIT-UP!\"',\n",
       " '\\t* Neutral',\n",
       " '32. \"BATMAN --ARROW --RESPOND TO AQUAMAN\\'S CALL: THE REST OF THE TEAM WILL TAKE OFF ON A MONSTER-HUNT AROUND NEW CARTHAGE!\"',\n",
       " '\\t* Neutral',\n",
       " '33. \"GUESS HE GOT OVER HIS MAD!\"',\n",
       " '\\t* Neutral',\n",
       " '34. \"I\\'LL REMAIN HERE WITH FLASH IN CASE HE REVIVES AGAIN!\"',\n",
       " '\\t* Neutral',\n",
       " '35. \"NEARING THE COUNTRY-SIDE SURROUNDING HUDSON UNIVERSITY…\"',\n",
       " '\\t* Neutral',\n",
       " '36. \"DOWN BELOW--DICK GRAYSON--\"',\n",
       " '\\t* Neutral',\n",
       " '37. \"R\"',\n",
       " '\\t* Neutral',\n",
       " '38. \"A']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions[0][\"content\"].split(\"\\n\") # pages 5, 6, 7, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Based on the provided transcription, I've analyzed the emotions expressed by the characters. Here's the list of emotions for each text utterance:\",\n",
       " '',\n",
       " '1. <text>NEARING THE COUNTRY-SIDE SURROUNDING HUDSON UNIVERSITY…</text> - Neutral',\n",
       " '2. <text>DOWN BELOW--DICK GRAYSON--</text> - Joy',\n",
       " '3. <text>--IN ROBIN-ACTION!</text> - Joy',\n",
       " '4. <text>R</text> - Neutral',\n",
       " '5. <text>AFTER MAKING CONTACT…</text> - Neutral',\n",
       " '6. <text>WHILE ON A CASE *, I HEARD RANGER RADIO-REPORTS OF A MARAUDING MONSTER --SO, I PULLED OUT MY CYCLE AND HEADED THIS WAY!</text> - Fear',\n",
       " \"7. <text>WHERE WAS THE MONSTER'S LAST-REPORTED SIGHTING?</text> - Neutral\",\n",
       " '8. <text> * AS DETAILED IN THE AUGUST BATMAN --\" VENGEANCE FOR A COP! \"</text> - Neutral',\n",
       " '9. <text>OVER THAT HILL-RISE ABOUT 20 MILES!</text> - Neutral',\n",
       " '10. <text>MIGHT AS WELL STASH MY BIKE AND HITCH ALONG WITH YOU!</text> - Neutral',\n",
       " '11. <text>THEN AS IS SO FREQUENTLY DUPLICATED ON THE TWIN-EARTHS…</text> - Neutral',\n",
       " \"12. <text>WELL… LONG AS BATMAN ISN'T HERE, YOU MIGHT HELP OUT A LITTLE--</text> - Neutral\",\n",
       " '13. <text>AND THOUGH UNSPOKEN, THE ROBIN-ANGER IS PRECISELY THE SAME!</text> - Anger',\n",
       " '14. <text>WHEWE LOOK AT THAT DESTRUCTION--TREES SCATTERED LIKE MATCHSTICKS!</text> - Fear',\n",
       " \"15. <text>HEY, WHAT'S MY POWER RING ZEROING IN ON?</text> - Surprise\"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_predictions[0][\"content\"].split(\"\\n\") page 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"After analyzing the transcription of the comics page, I've identified the emotions expressed by the characters. Here is the list of emotions:\",\n",
       " '',\n",
       " '1. Neutral',\n",
       " '2. Neutral',\n",
       " '3. Surprise',\n",
       " '4. Neutral',\n",
       " '5. Joy',\n",
       " '6. Surprise',\n",
       " '7. Neutral',\n",
       " '8. Neutral',\n",
       " '9. Neutral',\n",
       " '10. Neutral',\n",
       " '11. Joy',\n",
       " '12. Neutral',\n",
       " '13. Neutral',\n",
       " '14. Joy',\n",
       " '15. Neutral',\n",
       " '',\n",
       " \"Note that some of the emotions are expressed through the characters' reactions, tone, or dialogue, while others are implied through the context of the scene.\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_predictions[0][\"content\"].split(\"\\n\") page 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"After analyzing the transcription of the comics page, I've identified the emotions expressed by the characters. Here is the list of emotions in the corresponding classes:\",\n",
       " '',\n",
       " '1. <text>AN EMERGENCY SIGNAL CALLS FOR A SUPER-SPEED RESPONSE…</text> - Neutral',\n",
       " '2. <text>GREEN LANTERN--WHAT HAPPENED? LOOKS LIKE A TORNADO HIT YOU!</text> - Surprise',\n",
       " '3. <text>YEAH… A TORNADO… IN THE FORM OF A KID --A SWEET, INNOCENT, LOVABLE KID!</text> - Joy',\n",
       " '4. <text>\" AFTER ROBIN AND I WRAPPED UP A CASE NEAR HERE, I DECIDED TO TAKE A SOLO SIDE-TRIP TO CHECK UP ON SLAUGHTER SWAMP WHEN… \"</text> - Neutral',\n",
       " '5. <text>\" AS I SWOOPED DOWN TO HELP HIM, HE TURNED ON ME WITH A RAGING SNARL… \"</text> - Anger',\n",
       " '6. <text>THAT OVERGROWN KID SEEMS LOST--FRANTICALLY TRYING TO SMASH HIS WAY OUT…</text> - Fear',\n",
       " '7. <text>I TELE-SENSE YOU CAN BRING TEPPY TO ME!</text> - Neutral',\n",
       " '8. <text>WITH THAT, HE ATTACKED ME--WITH SURPRISING, STUPENDOUS STRENGTH… \"</text> - Surprise',\n",
       " '9. <text>WHEN I CAME TO, ROBIN WAS HERE--BUT MY POWER RING WAS GONE!</text> - Sadness',\n",
       " \"10. <text>SHOULDN'T BE HARD TO TRACK DOWN YOUR GO BACK ATTACKER!</text> - Neutral\",\n",
       " \"11. <text>THAT'S WHY I SIGNALLED YOU!</text> - Neutral\",\n",
       " '12. <text>BUT I ADVISE YOU TO TO HEAD-QUARTERS AND RECU-PERATE!</text> - Neutral',\n",
       " \"13. <text>USE MY ROBIN-CLIPPER TO GET THERE, GLiI'M STICKING WITH THE JSA!</text> - Joy\",\n",
       " \"14. <text>HMM… I SUPPOSE SO, ROBIN--SINCE YOU'RE HERE! YOU MAY AS WELL JOIN US, FILL IN FOR BATMAN--</text> - Neutral\",\n",
       " \"15. <text>YOU FORGET, CHAIRMAN HAWKMAN --I'VE BEEN ACCEPTED AS A FULL-FLEDGED JSA MEMBER!</text> - Joy\",\n",
       " '16. <text>MAN, WHAT A PATRONIZING ATTITUDE! GENERATION GAP STRIKES AGAIN!</text> - Disgust']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_predictions[0][\"content\"].split(\"\\n\") page 5"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[\"After analyzing the transcription of the comics page, I've identified the emotions expressed by each character in the given emotion classes: Anger, Disgust, Fear, Joy, Neutral, Sadness, and Surprise. Here is the list of emotions:\",\n",
    " '',\n",
    " '1. \"AN EMERGENCY SIGNAL CALLS FOR A SUPER-SPEED RESPONSE…\"',\n",
    " '\\t* Neutral',\n",
    " '2. \"GREEN LANTERN--WHAT HAPPENED? LOOKS LIKE A TORNADO HIT YOU!\"',\n",
    " '\\t* Neutral',\n",
    " '3. \"YEAH… A TORNADO… IN THE FORM OF A KID --A SWEET, INNOCENT, LOVABLE KID!\"',\n",
    " '\\t* Joy',\n",
    " '4. \"AFTER ROBIN AND I WRAPPED UP A CASE NEAR HERE, I DECIDED TO TAKE A SOLO SIDE-TRIP TO CHECK UP ON SLAUGHTER SWAMP WHEN…\"',\n",
    " '\\t* Neutral',\n",
    " '5. \"AS I SWOOPED DOWN TO HELP HIM, HE TURNED ON ME WITH A RAGING SNARL…\"',\n",
    " '\\t* Anger',\n",
    " '6. \"THAT OVERGROWN KID SEEMS LOST--FRANTICALLY TRYING TO SMASH HIS WAY OUT…\"',\n",
    " '\\t* Fear',\n",
    " '7. \"I TELE-SENSE YOU CAN BRING TEPPY TO ME!\"',\n",
    " '\\t* Neutral',\n",
    " '8. \"WITH THAT, HE ATTACKED ME--WITH SURPRISING, STUPENDOUS STRENGTH…\"',\n",
    " '\\t* Surprise',\n",
    " '9. \"WHEN I CAME TO, ROBIN WAS HERE--BUT MY POWER RING WAS GONE!\"',\n",
    " '\\t* Anger',\n",
    " '10. \"SHOULDN\\'T BE HARD TO TRACK DOWN YOUR GO BACK ATTACKER!\"',\n",
    " '\\t* Neutral',\n",
    " '11. \"THAT\\'S WHY I SIGNALLED YOU!\"',\n",
    " '\\t* Neutral',\n",
    " '12. \"BUT I ADVISE YOU TO TO HEAD-QUARTERS AND RECU-PERATE!\"',\n",
    " '\\t* Neutral',\n",
    " '13. \"USE MY ROBIN-CLIPPER TO GET THERE, GLI\\'M STICKING WITH THE JSA!\"',\n",
    " '\\t* Neutral',\n",
    " '14. \"HMM… I SUPPOSE SO, ROBIN--SINCE YOU\\'RE HERE! YOU MAY AS WELL JOIN US, FILL IN FOR BATMAN--\"',\n",
    " '\\t* Neutral',\n",
    " '15. \"YOU FORGET, CHAIRMAN HAWKMAN --I\\'VE BEEN ACCEPTED AS A FULL-FLEDGED JSA MEMBER!\"',\n",
    " '\\t* Joy',\n",
    " '16. \"MAN, WHAT A PATRONIZING ATTITUDE! GENERATION GAP STRIKES AGAIN!\"',\n",
    " '\\t* Disgust',\n",
    " '17. \"LEAVING THE SULKING ROBIN, WE RETURN ONCE MORE ΤΟ JUSTICE LEAGUE HEAD-QUARTERS…\"',\n",
    " '\\t* Neutral',\n",
    " '18. \"I FOUND THE MALLED FLASH NORTH OF GOTHAM CITY--\"',\n",
    " '\\t* Neutral',\n",
    " '19. \"THE READINGS ON THE THANAGARIAN METABOLIC REVIVER ARE TURNING POSITIVE! THE SPEEDSTER\\'S GONNA MAKE IT!\"',\n",
    " '\\t* Joy',\n",
    " '20. \"JUST THEN…\"',\n",
    " '\\t* Neutral',\n",
    " '21. \"OHH: WHAT\\'S ALL THE COMMOTION--?\"',\n",
    " '\\t* Surprise',\n",
    " '22. \"FLASH IS GOING-RUNNING --WILD!\"',\n",
    " '\\t* Surprise',\n",
    " '23. \"NEWLY ARRIVED BLACK CANARY AND GREEN ARROW WATCH IN STUNNED AMAZEMENT AS…\"',\n",
    " '\\t* Surprise',\n",
    " '24. \"CAUGHT UP TO HIM--UNNH--HE\\'S CONKED OUT AGAIN!\"',\n",
    " '\\t* Surprise',\n",
    " '25. \"FLASH STARTED TO SAY SOMETHING--BUT SO FAST, IT CAME OUT GARBLED:\"',\n",
    " '\\t* Surprise',\n",
    " '26. \"MY SUPER-HEARING CAUGHT ENOUGH TO HEAR, FLASH MUTTER ALIEN--MONSTER--NEW CARTHAGE!\"',\n",
    " '\\t* Surprise',\n",
    " '27. \"NEW CARTHAGE.? THAT\\'S WHERE--\"',\n",
    " '\\t* Neutral',\n",
    " '28. \"HUDSON --AND UNIVERSITY PICK 15-\"',\n",
    " '\\t* Neutral',\n",
    " '29. \"( ROBIN ) GRAYSON!\"',\n",
    " '\\t* Joy',\n",
    " '30. \"IT\\'S AQUAMAN ON THE ALARM--USING THE SPECIAL EMERGENCY CALL FOR BATMAN AND GREEN ARROW!\"',\n",
    " '\\t* Neutral',\n",
    " '31. \"THAT MEANS A SPLIT-UP!\"',\n",
    " '\\t* Neutral',\n",
    " '32. \"BATMAN --ARROW --RESPOND TO AQUAMAN\\'S CALL: THE REST OF THE TEAM WILL TAKE OFF ON A MONSTER-HUNT AROUND NEW CARTHAGE!\"',\n",
    " '\\t* Neutral',\n",
    " '33. \"GUESS HE GOT OVER HIS MAD!\"',\n",
    " '\\t* Neutral',\n",
    " '34. \"I\\'LL REMAIN HERE WITH FLASH IN CASE HE REVIVES AGAIN!\"',\n",
    " '\\t* Neutral',\n",
    " '35. \"NEARING THE COUNTRY-SIDE SURROUNDING HUDSON UNIVERSITY…\"',\n",
    " '\\t* Neutral',\n",
    " '36. \"DOWN BELOW--DICK GRAYSON--\"',\n",
    " '\\t* Neutral',\n",
    " '37. \"R\"',\n",
    " '\\t* Neutral',\n",
    " '38. \"A']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[\"After analyzing the transcription of the comics page, I've identified the emotions expressed by the characters. Here is the list of emotions:\",\n",
    " '',\n",
    " '1. Neutral',\n",
    " '2. Neutral',\n",
    " '3. Surprise',\n",
    " '4. Neutral',\n",
    " '5. Joy',\n",
    " '6. Surprise',\n",
    " '7. Neutral',\n",
    " '8. Neutral',\n",
    " '9. Neutral',\n",
    " '10. Neutral',\n",
    " '11. Joy',\n",
    " '12. Neutral',\n",
    " '13. Neutral',\n",
    " '14. Joy',\n",
    " '15. Neutral',\n",
    " '',\n",
    " \"Note that some of the emotions are expressed through the characters' reactions, tone, or dialogue, while others are implied through the context of the scene.\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[\"After analyzing the transcription of the comics page, I've identified the emotions expressed by the characters. Here is the list of emotions in the corresponding classes:\",\n",
    " '',\n",
    " '1. <text>AN EMERGENCY SIGNAL CALLS FOR A SUPER-SPEED RESPONSE…</text> - Neutral',\n",
    " '2. <text>GREEN LANTERN--WHAT HAPPENED? LOOKS LIKE A TORNADO HIT YOU!</text> - Surprise',\n",
    " '3. <text>YEAH… A TORNADO… IN THE FORM OF A KID --A SWEET, INNOCENT, LOVABLE KID!</text> - Joy',\n",
    " '4. <text>\" AFTER ROBIN AND I WRAPPED UP A CASE NEAR HERE, I DECIDED TO TAKE A SOLO SIDE-TRIP TO CHECK UP ON SLAUGHTER SWAMP WHEN… \"</text> - Neutral',\n",
    " '5. <text>\" AS I SWOOPED DOWN TO HELP HIM, HE TURNED ON ME WITH A RAGING SNARL… \"</text> - Anger',\n",
    " '6. <text>THAT OVERGROWN KID SEEMS LOST--FRANTICALLY TRYING TO SMASH HIS WAY OUT…</text> - Fear',\n",
    " '7. <text>I TELE-SENSE YOU CAN BRING TEPPY TO ME!</text> - Neutral',\n",
    " '8. <text>WITH THAT, HE ATTACKED ME--WITH SURPRISING, STUPENDOUS STRENGTH… \"</text> - Surprise',\n",
    " '9. <text>WHEN I CAME TO, ROBIN WAS HERE--BUT MY POWER RING WAS GONE!</text> - Sadness',\n",
    " \"10. <text>SHOULDN'T BE HARD TO TRACK DOWN YOUR GO BACK ATTACKER!</text> - Neutral\",\n",
    " \"11. <text>THAT'S WHY I SIGNALLED YOU!</text> - Neutral\",\n",
    " '12. <text>BUT I ADVISE YOU TO TO HEAD-QUARTERS AND RECU-PERATE!</text> - Neutral',\n",
    " \"13. <text>USE MY ROBIN-CLIPPER TO GET THERE, GLiI'M STICKING WITH THE JSA!</text> - Joy\",\n",
    " \"14. <text>HMM… I SUPPOSE SO, ROBIN--SINCE YOU'RE HERE! YOU MAY AS WELL JOIN US, FILL IN FOR BATMAN--</text> - Neutral\",\n",
    " \"15. <text>YOU FORGET, CHAIRMAN HAWKMAN --I'VE BEEN ACCEPTED AS A FULL-FLEDGED JSA MEMBER!</text> - Joy\",\n",
    " '16. <text>MAN, WHAT A PATRONIZING ATTITUDE! GENERATION GAP STRIKES AGAIN!</text> - Disgust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages = []\n",
    "# messages.append({\"role\": \"user\", \"content\": prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions = []\n",
    "# response = \"\"\n",
    "\n",
    "# for new_text in model.stream_chat(messages):\n",
    "#     #print(new_text, end=\"\", flush=True)\n",
    "#     response += new_text\n",
    "#     #print()\n",
    "#     test_predictions.append({\"role\": \"assistant\", \"content\": response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'assistant', 'content': ''},\n",
       " {'role': 'assistant', 'content': ''},\n",
       " {'role': 'assistant', 'content': \"I'm \"},\n",
       " {'role': 'assistant', 'content': \"I'm happy \"},\n",
       " {'role': 'assistant', 'content': \"I'm happy to \"},\n",
       " {'role': 'assistant', 'content': \"I'm happy to help \"},\n",
       " {'role': 'assistant', 'content': \"I'm happy to help with \"},\n",
       " {'role': 'assistant', 'content': \"I'm happy to help with the \"},\n",
       " {'role': 'assistant', 'content': \"I'm happy to help with the comics \"},\n",
       " {'role': 'assistant', 'content': \"I'm happy to help with the comics \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\n\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\n\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\n\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\n\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\n\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\n\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\n\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\nPlease \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\nPlease provide \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\nPlease provide the \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\nPlease provide the rest \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\nPlease provide the rest of \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\nPlease provide the rest of the \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\nPlease provide the rest of the \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\nPlease provide the rest of the transcription, \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\nPlease provide the rest of the transcription, and \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\nPlease provide the rest of the transcription, and \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\nPlease provide the rest of the transcription, and I'll \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\nPlease provide the rest of the transcription, and I'll be \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\nPlease provide the rest of the transcription, and I'll be happy \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\nPlease provide the rest of the transcription, and I'll be happy to \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\nPlease provide the rest of the transcription, and I'll be happy to help \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\nPlease provide the rest of the transcription, and I'll be happy to help you \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\nPlease provide the rest of the transcription, and I'll be happy to help you identify \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\nPlease provide the rest of the transcription, and I'll be happy to help you identify the \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\nPlease provide the rest of the transcription, and I'll be happy to help you identify the emotions \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\nPlease provide the rest of the transcription, and I'll be happy to help you identify the emotions for \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\nPlease provide the rest of the transcription, and I'll be happy to help you identify the emotions for each \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\nPlease provide the rest of the transcription, and I'll be happy to help you identify the emotions for each text \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\nPlease provide the rest of the transcription, and I'll be happy to help you identify the emotions for each text \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\nPlease provide the rest of the transcription, and I'll be happy to help you identify the emotions for each text \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\nPlease provide the rest of the transcription, and I'll be happy to help you identify the emotions for each text \"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm happy to help with the comics analysis! Since you've provided the transcription of a comics page, I'll assume that the page contains the following text utterances enclosed by <text></text> tags:\\n\\n<text>I am very sad.</text>\\n\\nBased on the given text utterance, I would identify the emotion as:\\n\\n* Target AC (int): 1 (Sadness)\\n* Source AC (int): 1 (The speaker themselves)\\n\\nSo, the argument component pair would be:\\n\\n[(1, 1)]\\n\\nPlease provide the rest of the transcription, and I'll be happy to help you identify the emotions for each text utterance!\"}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_prompts = []\n",
    "# test_grounds = []\n",
    "\n",
    "# for sample in test_dataset:\n",
    "#     test_prompts.append(\"\\nUser:\" + sample[\"instruction\"] + sample[\"input\"])\n",
    "#     test_grounds.append(sample[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions = []\n",
    "\n",
    "# for prompt in test_prompts:\n",
    "\n",
    "#     messages = []\n",
    "#     messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "#     response = \"\"\n",
    "    \n",
    "#     for new_text in model.stream_chat(messages):\n",
    "#         #print(new_text, end=\"\", flush=True)\n",
    "#         response += new_text\n",
    "#         #print()\n",
    "#     test_predictions.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "#     torch_gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(os.getcwd(), \"datasets\")\n",
    "\n",
    "# *** TRAIN DATASET NAME *** #\n",
    "\n",
    "train_dataset_name = \"PE_LI_train.json\"\n",
    "train_dataset_file = os.path.join(dataset_dir, train_dataset_name)\n",
    "\n",
    "# *** TEST DATASET NAME *** #\n",
    "\n",
    "test_dataset_name = \"PE_LI_test.json\"\n",
    "test_dataset_file = os.path.join(dataset_dir, test_dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgR3UFhB0Ifq"
   },
   "source": [
    "## Fine-tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# *** MODEL NAME ***\n",
    "\n",
    "base_model = \"unsloth/llama-3-8b-Instruct-bnb-4bit\"\n",
    "\n",
    "# with open(\"tmp.pkl\", \"rb\") as fh:\n",
    "        \n",
    "#         base_model = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# *** MODEL DIR ***\n",
    "model_name = f\"\"\"PE_LI_{base_model.split(\"/\")[1]}\"\"\"\n",
    "\n",
    "train_file = os.path.join(os.getcwd(), f\"\"\"cli_files/PE_LI_{base_model.split(\"/\")[1]}.json\"\"\")\n",
    "output_dir = os.path.join(os.getcwd(), \"models\", model_name)\n",
    "\n",
    "nb_epochs = 10 # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Utilisateurs/umushtaq/cli_files/PE_LI_llama-3-70b-Instruct-bnb-4bit.json'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_info_line =  {\n",
    "  \"file_name\": f\"{train_dataset_file}\",\n",
    "  \"columns\": {\n",
    "    \"prompt\": \"instruction\",\n",
    "    \"query\": \"input\",\n",
    "    \"response\": \"output\"\n",
    "  }\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': '/Utilisateurs/umushtaq/datasets/PE_LI_train.json',\n",
       " 'columns': {'prompt': 'instruction', 'query': 'input', 'response': 'output'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_info_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Utilisateurs/umushtaq'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"LLaMA-Factory/data/dataset_info.json\", 'r+') as fh:\n",
    "    file_data = json.load(fh)\n",
    "    file_data[\"persuasive_essays\"] = dataset_info_line\n",
    "    fh.seek(0)\n",
    "    json.dump(file_data, fh, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "CS0Qk5OR0i4Q",
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = dict(\n",
    "  stage=\"sft\",                           # do supervised fine-tuning\n",
    "  do_train=True,\n",
    "  model_name_or_path=base_model,         # use bnb-4bit-quantized Llama-3-8B-Instruct model\n",
    "  dataset=\"persuasive_essays\",           # use alpaca and identity datasets\n",
    "  template=\"llama3\",                     # use llama3 prompt template\n",
    "  finetuning_type=\"lora\",                # use LoRA adapters to save memory\n",
    "  lora_target=\"all\",                     # attach LoRA adapters to all linear layers\n",
    "  output_dir=output_dir,                 # the path to save LoRA adapters\n",
    "  overwrite_output_dir=True,             # overrides existing output contents\n",
    "  per_device_train_batch_size=2,         # the batch size\n",
    "  gradient_accumulation_steps=4,         # the gradient accumulation steps\n",
    "  lr_scheduler_type=\"cosine\",            # use cosine learning rate scheduler\n",
    "  logging_steps=10,                      # log every 10 steps\n",
    "  warmup_ratio=0.1,                      # use warmup scheduler\n",
    "  save_steps=1000,                       # save checkpoint every 1000 steps\n",
    "  learning_rate=5e-5,                    # the learning rate\n",
    "  num_train_epochs=nb_epochs,            # the epochs of training\n",
    "  max_samples=500,                       # use 500 examples in each dataset\n",
    "  max_grad_norm=1.0,                     # clip gradient norm to 1.0\n",
    "  quantization_bit=4,                    # use 4-bit QLoRA\n",
    "  loraplus_lr_ratio=16.0,                # use LoRA+ algorithm with lambda=16.0\n",
    "  fp16=True,                             # use float16 mixed precision training\n",
    "  report_to=\"none\"                       # discards wandb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json.dump(args, open(train_file, \"w\", encoding=\"utf-8\"), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Utilisateurs/umushtaq'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Utilisateurs/umushtaq/LLaMA-Factory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Utilisateurs/umushtaq/.conda/envs/llama-factory-notebook/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd LLaMA-Factory/\n",
    "!set train_file = train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Utilisateurs/umushtaq/cli_files/PE_LI_llama-3-70b-Instruct-bnb-4bit.json'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/05/2024 10:36:38 - WARNING - llamafactory.hparams.parser - We recommend enable `upcast_layernorm` in quantized training.\n",
      "06/05/2024 10:36:38 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: torch.float16\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-05 10:36:38,226 >> loading file tokenizer.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-70b-Instruct-bnb-4bit/snapshots/df8fab159e49c133bb4f074baeff4b303614b6d1/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-05 10:36:38,227 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-05 10:36:38,227 >> loading file special_tokens_map.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-70b-Instruct-bnb-4bit/snapshots/df8fab159e49c133bb4f074baeff4b303614b6d1/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-05 10:36:38,227 >> loading file tokenizer_config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-70b-Instruct-bnb-4bit/snapshots/df8fab159e49c133bb4f074baeff4b303614b6d1/tokenizer_config.json\n",
      "[WARNING|logging.py:314] 2024-06-05 10:36:38,584 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "06/05/2024 10:36:38 - INFO - llamafactory.data.template - Replace eos token: <|eot_id|>\n",
      "06/05/2024 10:36:38 - INFO - llamafactory.data.loader - Loading dataset /Utilisateurs/umushtaq/datasets/PE_LI_train.json...\n",
      "input_ids:\n",
      "[128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 18328, 13, 128009, 128006, 882, 128007, 271, 14711, 1472, 527, 459, 6335, 304, 14138, 26917, 13, 1472, 527, 2728, 264, 14646, 902, 5727, 5811, 6956, 44910, 555, 366, 1741, 1500, 1741, 29, 9681, 13, 4718, 3465, 374, 311, 10765, 5811, 4398, 1990, 5811, 6956, 304, 279, 14646, 13, 1472, 2011, 471, 264, 1160, 315, 5811, 3777, 13840, 304, 2768, 3645, 25, 18305, 5775, 10807, 320, 396, 705, 2592, 10807, 320, 396, 5850, 61453, 320, 5775, 10807, 320, 396, 705, 2592, 10807, 320, 396, 595, 2595, 14711, 5810, 374, 279, 14646, 1495, 25, 330, 2181, 374, 2744, 1071, 430, 10937, 649, 13750, 12192, 279, 4500, 315, 8752, 662, 763, 2015, 311, 18167, 304, 279, 10937, 1174, 5220, 3136, 311, 7417, 872, 3956, 323, 2532, 1174, 323, 439, 264, 1121, 1174, 279, 4459, 8396, 463, 2203, 388, 662, 4452, 1174, 994, 584, 4358, 279, 4360, 315, 10937, 477, 23915, 1174, 1148, 584, 527, 11920, 922, 374, 539, 279, 4459, 8396, 1174, 719, 279, 4500, 315, 459, 3927, 364, 274, 4459, 2324, 662, 5659, 420, 1486, 315, 1684, 1174, 358, 32620, 4510, 430, 366, 1741, 16, 11, 17559, 46644, 29, 584, 1288, 15866, 810, 12939, 311, 23915, 2391, 6156, 6873, 694, 1741, 16, 11, 17559, 46644, 29, 662, 702, 257, 128009, 128006, 78191, 128007, 271, 1318, 128009]\n",
      "inputs:\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "### You are an expert in Argument Mining. You are given a paragraph which contains argument components enclosed by <AC></AC> tags. Your task is to identify argument relations between argument components in the paragraph. You must return a list of argument component pairs in following format: [(target AC (int), source AC (int)),..., (target AC (int), source AC (int))]\n",
      "\n",
      "### Here is the paragraph text: \"It is always said that competition can effectively promote the development of economy. In order to survive in the competition, companies continue to improve their products and service, and as a result, the whole society prospers. However, when we discuss the issue of competition or cooperation, what we are concerned about is not the whole society, but the development of an individual's whole life. From this point of view, I firmly believe that <AC1, MajorClaim> we should attach more importance to cooperation during primary education </AC1, MajorClaim>.\"\n",
      "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "[]<|eot_id|>\n",
      "label_ids:\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1318, 128009]\n",
      "labels:\n",
      "[]<|eot_id|>\n",
      "/Utilisateurs/umushtaq/.conda/envs/llama-factory-notebook/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "[INFO|configuration_utils.py:733] 2024-06-05 10:36:39,230 >> loading configuration file config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-70b-Instruct-bnb-4bit/snapshots/df8fab159e49c133bb4f074baeff4b303614b6d1/config.json\n",
      "[INFO|configuration_utils.py:796] 2024-06-05 10:36:39,231 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"unsloth/llama-3-70b-Instruct-bnb-4bit\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 8192,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 28672,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 64,\n",
      "  \"num_hidden_layers\": 80,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"_load_in_4bit\": true,\n",
      "    \"_load_in_8bit\": false,\n",
      "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
      "    \"bnb_4bit_quant_type\": \"nf4\",\n",
      "    \"bnb_4bit_use_double_quant\": true,\n",
      "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "    \"llm_int8_has_fp16_weight\": false,\n",
      "    \"llm_int8_skip_modules\": null,\n",
      "    \"llm_int8_threshold\": 6.0,\n",
      "    \"load_in_4bit\": true,\n",
      "    \"load_in_8bit\": false,\n",
      "    \"quant_method\": \"bitsandbytes\"\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "06/05/2024 10:36:39 - INFO - llamafactory.model.utils.quantization - Loading ?-bit BITSANDBYTES-quantized model.\n",
      "[WARNING|quantization_config.py:393] 2024-06-05 10:36:39,312 >> Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "[INFO|modeling_utils.py:3474] 2024-06-05 10:36:39,315 >> loading weights file model.safetensors from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-70b-Instruct-bnb-4bit/snapshots/df8fab159e49c133bb4f074baeff4b303614b6d1/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1519] 2024-06-05 10:36:39,325 >> Instantiating LlamaForCausalLM model under default dtype torch.float16.\n",
      "[INFO|configuration_utils.py:962] 2024-06-05 10:36:39,327 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009\n",
      "}\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 6/6 [04:11<00:00, 41.89s/it]\n",
      "[INFO|modeling_utils.py:4280] 2024-06-05 10:40:52,054 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4288] 2024-06-05 10:40:52,055 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at unsloth/llama-3-70b-Instruct-bnb-4bit.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:917] 2024-06-05 10:40:52,237 >> loading configuration file generation_config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-70b-Instruct-bnb-4bit/snapshots/df8fab159e49c133bb4f074baeff4b303614b6d1/generation_config.json\n",
      "[INFO|configuration_utils.py:962] 2024-06-05 10:40:52,237 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128009\n",
      "  ]\n",
      "}\n",
      "\n",
      "06/05/2024 10:40:52 - INFO - llamafactory.model.utils.checkpointing - Gradient checkpointing enabled.\n",
      "06/05/2024 10:40:52 - INFO - llamafactory.model.utils.attention - Using torch SDPA for faster training and inference.\n",
      "06/05/2024 10:40:52 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n",
      "06/05/2024 10:40:52 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n",
      "06/05/2024 10:40:52 - INFO - llamafactory.model.utils.misc - Found linear modules: gate_proj,v_proj,q_proj,k_proj,up_proj,o_proj,down_proj\n",
      "06/05/2024 10:40:54 - INFO - llamafactory.model.loader - trainable params: 103546880 || all params: 70657253376 || trainable%: 0.1465\n",
      "[INFO|trainer.py:641] 2024-06-05 10:40:54,403 >> Using auto half precision backend\n",
      "06/05/2024 10:40:54 - WARNING - llamafactory.extras.callbacks - Previous trainer log in this folder will be deleted.\n",
      "06/05/2024 10:40:54 - INFO - llamafactory.train.utils - Using LoRA+ optimizer with loraplus lr ratio 16.00.\n",
      "[INFO|trainer.py:2078] 2024-06-05 10:40:54,738 >> ***** Running training *****\n",
      "[INFO|trainer.py:2079] 2024-06-05 10:40:54,738 >>   Num examples = 500\n",
      "[INFO|trainer.py:2080] 2024-06-05 10:40:54,738 >>   Num Epochs = 10\n",
      "[INFO|trainer.py:2081] 2024-06-05 10:40:54,738 >>   Instantaneous batch size per device = 2\n",
      "[INFO|trainer.py:2084] 2024-06-05 10:40:54,738 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:2085] 2024-06-05 10:40:54,738 >>   Gradient Accumulation steps = 4\n",
      "[INFO|trainer.py:2086] 2024-06-05 10:40:54,739 >>   Total optimization steps = 620\n",
      "[INFO|trainer.py:2087] 2024-06-05 10:40:54,753 >>   Number of trainable parameters = 103,546,880\n",
      "{'loss': 3.226, 'grad_norm': nan, 'learning_rate': 3.225806451612903e-06, 'epoch': 0.16}\n",
      "{'loss': 0.6351, 'grad_norm': 2.1450061798095703, 'learning_rate': 1.129032258064516e-05, 'epoch': 0.32}\n",
      "{'loss': 0.1453, 'grad_norm': 0.578214704990387, 'learning_rate': 1.935483870967742e-05, 'epoch': 0.48}\n",
      "{'loss': 0.1122, 'grad_norm': 0.28447863459587097, 'learning_rate': 2.7419354838709678e-05, 'epoch': 0.64}\n",
      "{'loss': 0.1146, 'grad_norm': 0.9580300450325012, 'learning_rate': 3.548387096774194e-05, 'epoch': 0.8}\n",
      "{'loss': 0.1063, 'grad_norm': 0.1578788161277771, 'learning_rate': 4.3548387096774194e-05, 'epoch': 0.96}\n",
      "{'loss': 0.0542, 'grad_norm': 0.8698496222496033, 'learning_rate': 4.99984151186201e-05, 'epoch': 1.12}\n",
      "{'loss': 0.0666, 'grad_norm': 0.2944815456867218, 'learning_rate': 4.994296536700177e-05, 'epoch': 1.28}\n",
      "{'loss': 0.0498, 'grad_norm': 0.2381005436182022, 'learning_rate': 4.980847237981281e-05, 'epoch': 1.44}\n",
      "{'loss': 0.0711, 'grad_norm': 0.39044588804244995, 'learning_rate': 4.9595362359820727e-05, 'epoch': 1.6}\n",
      "{'loss': 0.0646, 'grad_norm': 0.1747967153787613, 'learning_rate': 4.930431064394977e-05, 'epoch': 1.76}\n",
      "{'loss': 0.0524, 'grad_norm': 1.2636983394622803, 'learning_rate': 4.8936239563165895e-05, 'epoch': 1.92}\n",
      "{'loss': 0.0729, 'grad_norm': 0.25630924105644226, 'learning_rate': 4.849231551964771e-05, 'epoch': 2.08}\n",
      "{'loss': 0.044, 'grad_norm': 0.9223984479904175, 'learning_rate': 4.7973945290505766e-05, 'epoch': 2.24}\n",
      "{'loss': 0.0653, 'grad_norm': 0.19100305438041687, 'learning_rate': 4.7382771569763485e-05, 'epoch': 2.4}\n",
      "{'loss': 0.0396, 'grad_norm': 0.31995198130607605, 'learning_rate': 4.67206677627271e-05, 'epoch': 2.56}\n",
      "{'loss': 0.0434, 'grad_norm': 1.8670862913131714, 'learning_rate': 4.598973204924097e-05, 'epoch': 2.72}\n",
      "{'loss': 0.0581, 'grad_norm': 0.23322553932666779, 'learning_rate': 4.5192280734641626e-05, 'epoch': 2.88}\n",
      "{'loss': 0.0608, 'grad_norm': 0.466427206993103, 'learning_rate': 4.433084090948099e-05, 'epoch': 3.04}\n",
      "{'loss': 0.0316, 'grad_norm': 0.5307861566543579, 'learning_rate': 4.340814244127993e-05, 'epoch': 3.2}\n",
      "{'loss': 0.0296, 'grad_norm': 0.22763404250144958, 'learning_rate': 4.242710932368998e-05, 'epoch': 3.36}\n",
      "{'loss': 0.0238, 'grad_norm': 0.06124374642968178, 'learning_rate': 4.139085041047711e-05, 'epoch': 3.52}\n",
      "{'loss': 0.0291, 'grad_norm': 0.2619401812553406, 'learning_rate': 4.030264956369157e-05, 'epoch': 3.68}\n",
      "{'loss': 0.0596, 'grad_norm': 0.3867473602294922, 'learning_rate': 3.916595524724353e-05, 'epoch': 3.84}\n",
      "{'loss': 0.0298, 'grad_norm': 0.32813844084739685, 'learning_rate': 3.798436959886219e-05, 'epoch': 4.0}\n",
      "{'loss': 0.0163, 'grad_norm': 0.20136550068855286, 'learning_rate': 3.67616370150689e-05, 'epoch': 4.16}\n",
      "{'loss': 0.022, 'grad_norm': 0.35245245695114136, 'learning_rate': 3.5501632285337875e-05, 'epoch': 4.32}\n",
      "{'loss': 0.0195, 'grad_norm': 0.06873007118701935, 'learning_rate': 3.420834831304718e-05, 'epoch': 4.48}\n",
      "{'loss': 0.0264, 'grad_norm': 0.4389353394508362, 'learning_rate': 3.2885883462131394e-05, 'epoch': 4.64}\n",
      "{'loss': 0.0226, 'grad_norm': 0.05284583568572998, 'learning_rate': 3.153842856953417e-05, 'epoch': 4.8}\n",
      "{'loss': 0.0195, 'grad_norm': 0.008215083740651608, 'learning_rate': 3.0170253664617686e-05, 'epoch': 4.96}\n",
      "{'loss': 0.0089, 'grad_norm': 0.039733532816171646, 'learning_rate': 2.878569443761442e-05, 'epoch': 5.12}\n",
      "{'loss': 0.0121, 'grad_norm': 0.013104138895869255, 'learning_rate': 2.738913850000246e-05, 'epoch': 5.28}\n",
      "{'loss': 0.0055, 'grad_norm': 0.34326156973838806, 'learning_rate': 2.598501148034439e-05, 'epoch': 5.44}\n",
      "{'loss': 0.0166, 'grad_norm': 0.013290343806147575, 'learning_rate': 2.4577762999651726e-05, 'epoch': 5.6}\n",
      "{'loss': 0.0245, 'grad_norm': 0.30556026101112366, 'learning_rate': 2.3171852570718097e-05, 'epoch': 5.76}\n",
      "{'loss': 0.0137, 'grad_norm': 0.33349305391311646, 'learning_rate': 2.177173546610597e-05, 'epoch': 5.92}\n",
      "{'loss': 0.0058, 'grad_norm': 0.0209675133228302, 'learning_rate': 2.0381848599570276e-05, 'epoch': 6.08}\n",
      "{'loss': 0.0033, 'grad_norm': 0.04060908034443855, 'learning_rate': 1.9006596465660548e-05, 'epoch': 6.24}\n",
      "{'loss': 0.0066, 'grad_norm': 0.02464882656931877, 'learning_rate': 1.7650337182058084e-05, 'epoch': 6.4}\n",
      "{'loss': 0.0035, 'grad_norm': 0.040655963122844696, 'learning_rate': 1.6317368678879495e-05, 'epoch': 6.56}\n",
      "{'loss': 0.0164, 'grad_norm': 0.03762015700340271, 'learning_rate': 1.5011915078712251e-05, 'epoch': 6.72}\n",
      "{'loss': 0.0054, 'grad_norm': 0.11198166012763977, 'learning_rate': 1.3738113310543177e-05, 'epoch': 6.88}\n",
      "{'loss': 0.0074, 'grad_norm': 0.052349016070365906, 'learning_rate': 1.2500000000000006e-05, 'epoch': 7.04}\n",
      "{'loss': 0.0019, 'grad_norm': 0.008308791555464268, 'learning_rate': 1.1301498677450037e-05, 'epoch': 7.2}\n",
      "{'loss': 0.0022, 'grad_norm': 0.1131860539317131, 'learning_rate': 1.0146407344493186e-05, 'epoch': 7.36}\n",
      "{'loss': 0.009, 'grad_norm': 0.048669490963220596, 'learning_rate': 9.038386438250415e-06, 'epoch': 7.52}\n",
      "{'loss': 0.0022, 'grad_norm': 0.007564735133200884, 'learning_rate': 7.980947231588471e-06, 'epoch': 7.68}\n",
      "{'loss': 0.0023, 'grad_norm': 0.02222428470849991, 'learning_rate': 6.977440706039973e-06, 'epoch': 7.84}\n",
      "{'loss': 0.0008, 'grad_norm': 0.040543317794799805, 'learning_rate': 6.031046932680229e-06, 'epoch': 8.0}\n",
      "{'loss': 0.001, 'grad_norm': 0.03625575825572014, 'learning_rate': 5.1447649946122e-06, 'epoch': 8.16}\n",
      "{'loss': 0.0003, 'grad_norm': 0.007769430987536907, 'learning_rate': 4.32140348299504e-06, 'epoch': 8.32}\n",
      "{'loss': 0.001, 'grad_norm': 0.007068774662911892, 'learning_rate': 3.5635715967337223e-06, 'epoch': 8.48}\n",
      "{'loss': 0.0006, 'grad_norm': 0.007593849208205938, 'learning_rate': 2.8736708740346146e-06, 'epoch': 8.64}\n",
      "{'loss': 0.0044, 'grad_norm': 0.007439556531608105, 'learning_rate': 2.2538875820292347e-06, 'epoch': 8.8}\n",
      " 89%|██████████████████████████████████▌    | 550/620 [3:35:52<28:09, 24.14s/it]"
     ]
    }
   ],
   "source": [
    "!llamafactory-cli train $train_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVNaC-xS5N40"
   },
   "source": [
    "## Inference on the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.listdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oh8H9A_25SF9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %cd /content/LLaMA-Factory/\n",
    "\n",
    "args = dict(\n",
    "  model_name_or_path=base_model, # use bnb-4bit-quantized Llama-3-8B-Instruct model\n",
    "  adapter_name_or_path=output_dir,            # load the saved LoRA adapters\n",
    "  template=\"llama3\",                     # same to the one in training\n",
    "  finetuning_type=\"lora\",                  # same to the one in training\n",
    "  quantization_bit=4,                    # load 4-bit quantized model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ChatModel(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(test_dataset_file, \"r+\") as fh:\n",
    "    test_dataset = json.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_prompts = []\n",
    "test_grounds = []\n",
    "\n",
    "for sample in test_dataset:\n",
    "    test_prompts.append(\"\\nUser:\" + sample[\"instruction\"] + sample[\"input\"])\n",
    "    test_grounds.append(sample[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_predictions = []\n",
    "\n",
    "for prompt in test_prompts:\n",
    "\n",
    "    messages = []\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    response = \"\"\n",
    "    \n",
    "    for new_text in model.stream_chat(messages):\n",
    "        #print(new_text, end=\"\", flush=True)\n",
    "        response += new_text\n",
    "        #print()\n",
    "    test_predictions.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "    torch_gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# next(model.engine.model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(output_dir, f\"\"\"PE_LI_results_{nb_epochs}.pickle\"\"\"), 'wb') as fh:\n",
    "    results_d = {\"ground_truths\": test_grounds,\n",
    "                 \"predictions\": test_predictions    \n",
    "        \n",
    "    }\n",
    "    pickle.dump(results_d, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_preds = []\n",
    "for prediction in test_predictions:\n",
    "    test_preds.append(prediction[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = [ast.literal_eval(inner_list) for inner_list in test_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe_df = pd.read_csv(os.path.abspath(\"datasets/PE_data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split = pd.read_csv(\"datasets/train-test-split.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe_df['split'] = pe_df['essay_id'].map(df_split['SET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ac_count(x):\n",
    "\n",
    "    return len(ast.literal_eval(x.AC_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe_df[\"AC_count\"] = pe_df.apply(lambda x: get_ac_count(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe_df = pe_df[pe_df.AC_count > 0].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_possible_pairs(x):\n",
    "\n",
    "    pairs_l = []\n",
    "\n",
    "    ac_count = x.AC_count\n",
    "    ar_pairs = ast.literal_eval(x.AR_pairs)\n",
    "    \n",
    "    for i in range(ac_count):\n",
    "        for j in range(ac_count):\n",
    "            if i != j:\n",
    "                pair = (i, j)\n",
    "                if pair in ar_pairs:\n",
    "                    pairs_l.append((i, j, \"Rel\"))\n",
    "                else:\n",
    "                    pairs_l.append((i, j, \"N-Rel\"))\n",
    "\n",
    "    return pairs_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_all_possible_pairs(pe_df.iloc[1761])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe_df[\"LI_grounds\"] = pe_df.apply(lambda x: get_all_possible_pairs(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LI_grounds_l = list(pe_df[pe_df.split == \"TEST\"].reset_index().LI_grounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LI_grounds_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(LI_grounds_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_preds(test_preds, LI_grounds_l):\n",
    "\n",
    "    if len(test_preds) != len(LI_grounds_l):\n",
    "        print(\"error in preds length\")\n",
    "\n",
    "    preds_pairs_l = []\n",
    "\n",
    "    for l_1, l_2 in zip(test_preds, LI_grounds_l):\n",
    "        para_list = []\n",
    "        for i, j, _ in l_2:\n",
    "            pair = (i, j)\n",
    "            if pair in l_1:\n",
    "                para_list.append((i, j, \"Rel\"))\n",
    "            else:\n",
    "                para_list.append((i, j, \"N-Rel\"))\n",
    "\n",
    "        preds_pairs_l.append(para_list)\n",
    "\n",
    "    return preds_pairs_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LI_preds_l = process_preds(test_preds, LI_grounds_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check: len(LI_grounds_l) == len(LI_preds_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LI_preds = [item for row in LI_preds_l for item in row]\n",
    "LI_grounds = [item for row in LI_grounds_l for item in row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check: len(LI_preds) == len(LI_grounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LI_preds = [x[2] for x in LI_preds]\n",
    "LI_grounds = [x[2] for x in LI_grounds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(LI_grounds, LI_preds, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"\"\"{output_dir}/classification_report.pickle\"\"\", 'wb') as fh:\n",
    "    \n",
    "    pickle.dump(classification_report(LI_grounds, LI_preds, output_dict=True), fh)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "186 correct 0.2 epochs, with val separated\n",
    "287 correct 10 epochs, with val separated\n",
    "287 correct 10 epochs, val not separated"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
