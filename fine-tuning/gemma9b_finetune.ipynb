{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oHFCsV0z-Jw"
   },
   "source": [
    "# Finetune LLaMA 3 on the AbstRCT dataset on the ATC task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lr7rB3szzhtx"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "giM74oK1rRIH",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/scratch/umushtaq/am_work/AbstRCT_FT/LLaMA-Factory\n",
      "CITATION.cff  Makefile      \u001b[0m\u001b[01;34massets\u001b[0m/  \u001b[01;34mevaluation\u001b[0m/     requirements.txt  \u001b[01;34msrc\u001b[0m/\n",
      "LICENSE       README.md     \u001b[01;34mdata\u001b[0m/    \u001b[01;34mexamples\u001b[0m/       \u001b[01;34mscripts\u001b[0m/          \u001b[01;34mtests\u001b[0m/\n",
      "MANIFEST.in   README_zh.md  \u001b[01;34mdocker\u001b[0m/  pyproject.toml  setup.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///nfs/scratch/umushtaq/am_work/AbstRCT_FT/LLaMA-Factory\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers>=4.41.2 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (4.42.3)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (2.20.0)\n",
      "Requirement already satisfied: accelerate>=0.30.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (0.31.0)\n",
      "Requirement already satisfied: peft>=0.11.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (0.11.1)\n",
      "Requirement already satisfied: trl>=0.8.6 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (0.9.4)\n",
      "Requirement already satisfied: gradio>=4.0.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (4.37.2)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (2.2.2)\n",
      "Requirement already satisfied: scipy in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (1.14.0)\n",
      "Requirement already satisfied: einops in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (0.8.0)\n",
      "Requirement already satisfied: sentencepiece in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (0.2.0)\n",
      "Requirement already satisfied: tiktoken in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (0.7.0)\n",
      "Requirement already satisfied: protobuf in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (5.27.2)\n",
      "Requirement already satisfied: uvicorn in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (0.30.1)\n",
      "Requirement already satisfied: pydantic in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (2.8.2)\n",
      "Requirement already satisfied: fastapi in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (0.111.0)\n",
      "Requirement already satisfied: sse-starlette in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (2.1.2)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (3.9.0)\n",
      "Requirement already satisfied: fire in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (0.6.0)\n",
      "Requirement already satisfied: packaging in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (24.1)\n",
      "Requirement already satisfied: pyyaml in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (6.0.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (1.26.4)\n",
      "Requirement already satisfied: bitsandbytes>=0.39.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (0.43.1)\n",
      "Requirement already satisfied: torch>=1.13.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (2.3.1)\n",
      "Requirement already satisfied: psutil in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from accelerate>=0.30.1->llamafactory==0.8.3.dev0) (6.0.0)\n",
      "Requirement already satisfied: huggingface-hub in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from accelerate>=0.30.1->llamafactory==0.8.3.dev0) (0.23.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from accelerate>=0.30.1->llamafactory==0.8.3.dev0) (0.4.3)\n",
      "Requirement already satisfied: filelock in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (3.15.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets>=2.16.0->llamafactory==0.8.3.dev0) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (3.9.5)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (5.3.0)\n",
      "Requirement already satisfied: ffmpy in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.3.2)\n",
      "Requirement already satisfied: gradio-client==1.0.2 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (1.0.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.27.0)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (6.4.0)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (2.1.5)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (3.10.5)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (10.3.0)\n",
      "Requirement already satisfied: pydub in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.0.9)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.5.0)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.12.3)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (4.12.2)\n",
      "Requirement already satisfied: urllib3~=2.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (2.2.2)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio-client==1.0.2->gradio>=4.0.0->llamafactory==0.8.3.dev0) (11.0.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from matplotlib>=3.7.0->llamafactory==0.8.3.dev0) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from matplotlib>=3.7.0->llamafactory==0.8.3.dev0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from matplotlib>=3.7.0->llamafactory==0.8.3.dev0) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from matplotlib>=3.7.0->llamafactory==0.8.3.dev0) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from matplotlib>=3.7.0->llamafactory==0.8.3.dev0) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from matplotlib>=3.7.0->llamafactory==0.8.3.dev0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from pandas>=2.0.0->llamafactory==0.8.3.dev0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from pandas>=2.0.0->llamafactory==0.8.3.dev0) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from pydantic->llamafactory==0.8.3.dev0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from pydantic->llamafactory==0.8.3.dev0) (2.20.1)\n",
      "Requirement already satisfied: sympy in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (1.12.1)\n",
      "Requirement already satisfied: networkx in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (3.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.1->llamafactory==0.8.3.dev0) (12.5.40)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from transformers>=4.41.2->llamafactory==0.8.3.dev0) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from transformers>=4.41.2->llamafactory==0.8.3.dev0) (0.19.1)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from trl>=0.8.6->llamafactory==0.8.3.dev0) (0.8.5)\n",
      "Requirement already satisfied: click>=7.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from uvicorn->llamafactory==0.8.3.dev0) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from uvicorn->llamafactory==0.8.3.dev0) (0.14.0)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from fastapi->llamafactory==0.8.3.dev0) (0.37.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from fastapi->llamafactory==0.8.3.dev0) (0.0.4)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from fastapi->llamafactory==0.8.3.dev0) (5.10.0)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from fastapi->llamafactory==0.8.3.dev0) (2.2.0)\n",
      "Requirement already satisfied: six in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from fire->llamafactory==0.8.3.dev0) (1.16.0)\n",
      "Requirement already satisfied: termcolor in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from fire->llamafactory==0.8.3.dev0) (2.4.0)\n",
      "Requirement already satisfied: anyio in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from sse-starlette->llamafactory==0.8.3.dev0) (4.4.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.8.3.dev0) (4.22.0)\n",
      "Requirement already satisfied: toolz in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.12.1)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from email_validator>=2.0.0->fastapi->llamafactory==0.8.3.dev0) (2.6.1)\n",
      "Requirement already satisfied: idna>=2.0.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from email_validator>=2.0.0->fastapi->llamafactory==0.8.3.dev0) (3.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->llamafactory==0.8.3.dev0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->llamafactory==0.8.3.dev0) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->llamafactory==0.8.3.dev0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->llamafactory==0.8.3.dev0) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->llamafactory==0.8.3.dev0) (1.9.4)\n",
      "Requirement already satisfied: certifi in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.8.3.dev0) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.8.3.dev0) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.8.3.dev0) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.16.0->llamafactory==0.8.3.dev0) (3.3.2)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.8.3.dev0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.8.3.dev0) (13.7.1)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from tyro>=0.5.11->trl>=0.8.6->llamafactory==0.8.3.dev0) (0.16)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from tyro>=0.5.11->trl>=0.8.6->llamafactory==0.8.3.dev0) (1.7.1)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from uvicorn[standard]>=0.12.0->fastapi->llamafactory==0.8.3.dev0) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from uvicorn[standard]>=0.12.0->fastapi->llamafactory==0.8.3.dev0) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from uvicorn[standard]>=0.12.0->fastapi->llamafactory==0.8.3.dev0) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from uvicorn[standard]>=0.12.0->fastapi->llamafactory==0.8.3.dev0) (0.22.0)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from sympy->torch>=1.13.1->llamafactory==0.8.3.dev0) (1.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.8.3.dev0) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.18.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.8.3.dev0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.8.3.dev0) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.1.2)\n",
      "Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: llamafactory\n",
      "  Building editable for llamafactory (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llamafactory: filename=llamafactory-0.8.3.dev0-0.editable-py3-none-any.whl size=20653 sha256=bfafc777a1ad32dd227eb86a8db2e77028583bb9069fcba3c9ab4405b42798f5\n",
      "  Stored in directory: /tmp/SLURM_JOB_18644/pip-ephem-wheel-cache-k50rp7nh/wheels/cc/79/40/b648d67148324cfef434e2e558b01fdde202a02caa56a7d50c\n",
      "Successfully built llamafactory\n",
      "Installing collected packages: llamafactory\n",
      "  Attempting uninstall: llamafactory\n",
      "    Found existing installation: llamafactory 0.8.3.dev0\n",
      "    Uninstalling llamafactory-0.8.3.dev0:\n",
      "      Successfully uninstalled llamafactory-0.8.3.dev0\n",
      "Successfully installed llamafactory-0.8.3.dev0\n"
     ]
    }
   ],
   "source": [
    "# %cd ..\n",
    "# %rm -rf LLaMA-Factory\n",
    "# !git clone https://github.com/hiyouga/LLaMA-Factory.git\n",
    "# %cd LLaMA-Factory\n",
    "# %ls\n",
    "# !pip install -e .[torch,bitsandbytes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pydantic 2.8.2\n",
      "Uninstalling pydantic-2.8.2:\n",
      "  Successfully uninstalled pydantic-2.8.2\n",
      "Collecting pydantic==1.10.9\n",
      "  Using cached pydantic-1.10.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (147 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from pydantic==1.10.9) (4.12.2)\n",
      "Using cached pydantic-1.10.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Installing collected packages: pydantic\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradio 4.37.2 requires pydantic>=2.0, but you have pydantic 1.10.9 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pydantic-1.10.9\n",
      "Found existing installation: gradio 4.37.2\n",
      "Uninstalling gradio-4.37.2:\n",
      "  Successfully uninstalled gradio-4.37.2\n",
      "Collecting gradio==3.48.0\n",
      "  Using cached gradio-3.48.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio==3.48.0) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio==3.48.0) (5.3.0)\n",
      "Requirement already satisfied: fastapi in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio==3.48.0) (0.111.0)\n",
      "Requirement already satisfied: ffmpy in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio==3.48.0) (0.3.2)\n",
      "Collecting gradio-client==0.6.1 (from gradio==3.48.0)\n",
      "  Using cached gradio_client-0.6.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio==3.48.0) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.14.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio==3.48.0) (0.23.4)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio==3.48.0) (6.4.0)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio==3.48.0) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio==3.48.0) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio==3.48.0) (3.9.0)\n",
      "Requirement already satisfied: numpy~=1.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio==3.48.0) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio==3.48.0) (3.10.5)\n",
      "Requirement already satisfied: packaging in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio==3.48.0) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio==3.48.0) (2.2.2)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio==3.48.0) (10.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio==3.48.0) (1.10.9)\n",
      "Requirement already satisfied: pydub in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio==3.48.0) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio==3.48.0) (0.0.9)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio==3.48.0) (6.0.1)\n",
      "Requirement already satisfied: requests~=2.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio==3.48.0) (2.32.3)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio==3.48.0) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio==3.48.0) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio==3.48.0) (0.30.1)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio==3.48.0) (11.0.3)\n",
      "Requirement already satisfied: fsspec in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio-client==0.6.1->gradio==3.48.0) (2024.5.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio==3.48.0) (4.22.0)\n",
      "Requirement already satisfied: toolz in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio==3.48.0) (0.12.1)\n",
      "Requirement already satisfied: filelock in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from huggingface-hub>=0.14.0->gradio==3.48.0) (3.15.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from huggingface-hub>=0.14.0->gradio==3.48.0) (4.66.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.48.0) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.48.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.48.0) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.48.0) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.48.0) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.48.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio==3.48.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio==3.48.0) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from requests~=2.0->gradio==3.48.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from requests~=2.0->gradio==3.48.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from requests~=2.0->gradio==3.48.0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from requests~=2.0->gradio==3.48.0) (2024.6.2)\n",
      "Requirement already satisfied: click>=7.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from uvicorn>=0.14.0->gradio==3.48.0) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from uvicorn>=0.14.0->gradio==3.48.0) (0.14.0)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from fastapi->gradio==3.48.0) (0.37.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from fastapi->gradio==3.48.0) (0.0.4)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from fastapi->gradio==3.48.0) (5.10.0)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from fastapi->gradio==3.48.0) (2.2.0)\n",
      "Requirement already satisfied: anyio in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from httpx->gradio==3.48.0) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from httpx->gradio==3.48.0) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from httpx->gradio==3.48.0) (1.3.1)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from email_validator>=2.0.0->fastapi->gradio==3.48.0) (2.6.1)\n",
      "Requirement already satisfied: typer>=0.12.3 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from fastapi-cli>=0.0.2->fastapi->gradio==3.48.0) (0.12.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.48.0) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.48.0) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.48.0) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.48.0) (0.18.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==3.48.0) (1.16.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio==3.48.0) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio==3.48.0) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio==3.48.0) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio==3.48.0) (0.22.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->gradio==3.48.0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->gradio==3.48.0) (13.7.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->gradio==3.48.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->gradio==3.48.0) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->gradio==3.48.0) (0.1.2)\n",
      "Using cached gradio-3.48.0-py3-none-any.whl (20.3 MB)\n",
      "Using cached gradio_client-0.6.1-py3-none-any.whl (299 kB)\n",
      "Installing collected packages: gradio-client, gradio\n",
      "  Attempting uninstall: gradio-client\n",
      "    Found existing installation: gradio_client 1.0.2\n",
      "    Uninstalling gradio_client-1.0.2:\n",
      "      Successfully uninstalled gradio_client-1.0.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llamafactory 0.8.3.dev0 requires gradio>=4.0.0, but you have gradio 3.48.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed gradio-3.48.0 gradio-client-0.6.1\n",
      "Found existing installation: bitsandbytes 0.43.1\n",
      "Uninstalling bitsandbytes-0.43.1:\n",
      "  Successfully uninstalled bitsandbytes-0.43.1\n",
      "Collecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: torch in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from bitsandbytes) (2.3.1)\n",
      "Requirement already satisfied: numpy in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: filelock in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch->bitsandbytes) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch->bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch->bitsandbytes) (1.12.1)\n",
      "Requirement already satisfied: networkx in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch->bitsandbytes) (2024.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch->bitsandbytes) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch->bitsandbytes) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch->bitsandbytes) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch->bitsandbytes) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch->bitsandbytes) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch->bitsandbytes) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch->bitsandbytes) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch->bitsandbytes) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.5.40)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "Using cached bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.43.1\n",
      "Requirement already satisfied: tqdm in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (4.66.4)\n",
      "Requirement already satisfied: ipywidgets in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (8.1.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from ipywidgets) (8.25.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.11 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from ipywidgets) (4.0.11)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from ipywidgets) (3.0.11)\n",
      "Requirement already satisfied: decorator in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip uninstall -y pydantic\n",
    "# !pip install pydantic==1.10.9 # \n",
    "\n",
    "# !pip uninstall -y gradio\n",
    "# !pip install gradio==3.48.0\n",
    "\n",
    "# !pip uninstall -y bitsandbytes\n",
    "# !pip install --upgrade bitsandbytes\n",
    "\n",
    "# !pip install tqdm\n",
    "# !pip install ipywidgets\n",
    "# !pip install scikit-learn\n",
    "\n",
    "# Restart kernel afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from llamafactory.chat import ChatModel\n",
    "from llamafactory.extras.misc import torch_gc\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:    \n",
    "    assert torch.cuda.is_available() is True\n",
    "    \n",
    "except AssertionError:\n",
    "    \n",
    "    print(\"Please set up a GPU before using LLaMA Factory...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jul  6 17:26:13 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA H100 PCIe               Off |   00000000:82:00.0 Off |                    0 |\n",
      "| N/A   60C    P0             94W /  350W |       4MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA H100 PCIe               Off |   00000000:E3:00.0 Off |                    0 |\n",
      "| N/A   61C    P0             93W /  350W |       4MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/umushtaq/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "key = \"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\"\n",
    "login(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TeYs5Lz-QJYk"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/scratch/umushtaq/am_work/AbstRCT_FT'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'AbstRCT_FT'\n",
      "/nfs/scratch/umushtaq/am_work/AbstRCT_FT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages/IPython/core/magics/osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    }
   ],
   "source": [
    "%cd AbstRCT_FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** MODEL NAME ***\n",
    "\n",
    "base_model = \"meta-llama/Meta-Llama-3-70B-Instruct\"\n",
    "\n",
    "# with open(\"tmp.pkl\", \"rb\") as fh:\n",
    "        \n",
    "#         l = pickle.load(fh)\n",
    "#         base_model = l[0]\n",
    "#         train_dataset_name = l[1]\n",
    "#         test_dataset_name = l[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(os.getcwd(), \"datasets\")\n",
    "\n",
    "# *** TRAIN DATASET NAME *** #\n",
    "\n",
    "train_dataset_name = \"abstRCT_ATC_train_neo.json\"\n",
    "train_dataset_file = os.path.join(dataset_dir, train_dataset_name)\n",
    "\n",
    "# *** TEST DATASET NAME *** #\n",
    "\n",
    "# test_dataset_name = \"abstRCT_ATC_test_neo.json\"\n",
    "# test_dataset_file = os.path.join(dataset_dir, test_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(base_model, train_dataset_file, test_dataset_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgR3UFhB0Ifq"
   },
   "source": [
    "## Fine-tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# *** MODEL DIR ***\n",
    "model_name = f\"\"\"{train_dataset_name.split(\".\")[0].split(\"train\")[0]}{base_model.split(\"/\")[1]}\"\"\"\n",
    "\n",
    "train_file = os.path.join(os.getcwd(), f\"\"\"cli_files/{train_dataset_name.split(\".\")[0].split(\"train\")[0]}{base_model.split(\"/\")[1]}.json\"\"\")\n",
    "output_dir = os.path.join(os.getcwd(), \"models\", model_name)\n",
    "\n",
    "nb_epochs = 10 # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/scratch/umushtaq/am_work/AbstRCT_FT/models/abstRCT_ATC_Meta-Llama-3-70B-Instruct'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abstRCT_ATC_Meta-Llama-3-70B-Instruct'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/scratch/umushtaq/am_work/AbstRCT_FT/cli_files/abstRCT_ATC_Meta-Llama-3-70B-Instruct.json'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_info_line =  {\n",
    "  \"file_name\": f\"{train_dataset_file}\",\n",
    "  \"columns\": {\n",
    "    \"prompt\": \"instruction\",\n",
    "    \"query\": \"input\",\n",
    "    \"response\": \"output\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': '/nfs/scratch/umushtaq/am_work/AbstRCT_FT/datasets/abstRCT_ATC_train_neo.json',\n",
       " 'columns': {'prompt': 'instruction', 'query': 'input', 'response': 'output'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_info_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/scratch/umushtaq/am_work/AbstRCT_FT'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"LLaMA-Factory/data/dataset_info.json\", \"r\") as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "\n",
    "data[\"abstRCT\"] = dataset_info_line\n",
    "\n",
    "with open(\"LLaMA-Factory/data/dataset_info.json\", \"w\") as jsonFile:\n",
    "    json.dump(data, jsonFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create download line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_downloads = os.path.join(os.getcwd(), \"model_downloads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/scratch/umushtaq/am_work/AbstRCT_FT/model_downloads'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "CS0Qk5OR0i4Q",
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = dict(\n",
    "  stage=\"sft\",                           # do supervised fine-tuning\n",
    "  do_train=True,\n",
    "  model_name_or_path=base_model,         # use bnb-4bit-quantized Llama-3-8B-Instruct model\n",
    "  dataset=\"abstRCT\",                     # use alpaca and identity datasets\n",
    "  cache_dir=model_downloads,\n",
    "  template=\"llama3\",                     # use llama3 prompt template\n",
    "  finetuning_type=\"lora\",                # use LoRA adapters to save memory\n",
    "  lora_target=\"all\",                     # attach LoRA adapters to all linear layers\n",
    "  output_dir=output_dir,                 # the path to save LoRA adapters\n",
    "  overwrite_output_dir=True,             # overrides existing output contents\n",
    "  per_device_train_batch_size=2,         # the batch size\n",
    "  gradient_accumulation_steps=4,         # the gradient accumulation steps\n",
    "  lr_scheduler_type=\"cosine\",            # use cosine learning rate scheduler\n",
    "  logging_steps=10,                      # log every 10 steps\n",
    "  warmup_ratio=0.1,                      # use warmup scheduler\n",
    "  save_steps=3000,                       # save checkpoint every 1000 steps\n",
    "  learning_rate=5e-5,                    # the learning rate\n",
    "  num_train_epochs=nb_epochs,            # the epochs of training\n",
    "  max_samples=2000,                       # use 500 examples in each dataset\n",
    "  max_grad_norm=1.0,                     # clip gradient norm to 1.0\n",
    "  quantization_bit=4,                    # use 4-bit QLoRA\n",
    "  loraplus_lr_ratio=16.0,                # use LoRA+ algorithm with lambda=16.0\n",
    "  fp16=True,                             # use float16 mixed precision training\n",
    "  report_to=\"none\"                       # discards wandb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json.dump(args, open(train_file, \"w\", encoding=\"utf-8\"), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/scratch/umushtaq/am_work/AbstRCT_FT'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/scratch/umushtaq/am_work/AbstRCT_FT/LLaMA-Factory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd LLaMA-Factory/\n",
    "!set train_file = train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/scratch/umushtaq/am_work/AbstRCT_FT/cli_files/abstRCT_ATC_Meta-Llama-3-70B-Instruct.json'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/06/2024 17:26:54 - INFO - llamafactory.cli - Initializing distributed tasks at: 127.0.0.1:24213\n",
      "W0706 17:26:55.243000 140156288614912 torch/distributed/run.py:757] \n",
      "W0706 17:26:55.243000 140156288614912 torch/distributed/run.py:757] *****************************************\n",
      "W0706 17:26:55.243000 140156288614912 torch/distributed/run.py:757] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0706 17:26:55.243000 140156288614912 torch/distributed/run.py:757] *****************************************\n",
      "07/06/2024 17:27:02 - WARNING - llamafactory.hparams.parser - We recommend enable `upcast_layernorm` in quantized training.\n",
      "07/06/2024 17:27:02 - WARNING - llamafactory.hparams.parser - `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.\n",
      "07/06/2024 17:27:02 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, compute dtype: torch.float16\n",
      "07/06/2024 17:27:02 - WARNING - llamafactory.hparams.parser - We recommend enable `upcast_layernorm` in quantized training.\n",
      "07/06/2024 17:27:02 - WARNING - llamafactory.hparams.parser - `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.\n",
      "07/06/2024 17:27:02 - INFO - llamafactory.hparams.parser - Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True, compute dtype: torch.float16\n",
      "[INFO|tokenization_utils_base.py:2161] 2024-07-06 17:27:02,769 >> loading file tokenizer.json from cache at /nfs/scratch/umushtaq/am_work/AbstRCT_FT/model_downloads/models--meta-llama--Meta-Llama-3-70B-Instruct/snapshots/7129260dd854a80eb10ace5f61c20324b472b31c/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2161] 2024-07-06 17:27:02,769 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2161] 2024-07-06 17:27:02,769 >> loading file special_tokens_map.json from cache at /nfs/scratch/umushtaq/am_work/AbstRCT_FT/model_downloads/models--meta-llama--Meta-Llama-3-70B-Instruct/snapshots/7129260dd854a80eb10ace5f61c20324b472b31c/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2161] 2024-07-06 17:27:02,769 >> loading file tokenizer_config.json from cache at /nfs/scratch/umushtaq/am_work/AbstRCT_FT/model_downloads/models--meta-llama--Meta-Llama-3-70B-Instruct/snapshots/7129260dd854a80eb10ace5f61c20324b472b31c/tokenizer_config.json\n",
      "[WARNING|logging.py:313] 2024-07-06 17:27:03,093 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "07/06/2024 17:27:03 - INFO - llamafactory.data.template - Replace eos token: <|eot_id|>\n",
      "07/06/2024 17:27:03 - INFO - llamafactory.data.template - Add pad token: <|eot_id|>\n",
      "07/06/2024 17:27:03 - INFO - llamafactory.data.loader - Loading dataset /nfs/scratch/umushtaq/am_work/AbstRCT_FT/datasets/abstRCT_ATC_train_neo.json...\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "07/06/2024 17:27:03 - INFO - llamafactory.data.template - Replace eos token: <|eot_id|>\n",
      "07/06/2024 17:27:03 - INFO - llamafactory.data.template - Add pad token: <|eot_id|>\n",
      "07/06/2024 17:27:05 - INFO - llamafactory.data.loader - Loading dataset /nfs/scratch/umushtaq/am_work/AbstRCT_FT/datasets/abstRCT_ATC_train_neo.json...\n",
      "input_ids:\n",
      "[128000, 128006, 882, 128007, 271, 14711, 1472, 527, 459, 6335, 304, 6593, 6492, 13, 1472, 527, 2728, 279, 8278, 315, 264, 4288, 14400, 9269, 902, 5727, 49926, 5811, 6956, 44910, 555, 366, 1741, 1500, 1741, 29, 9681, 13, 4718, 3465, 374, 311, 49229, 1855, 5811, 6956, 304, 279, 9071, 439, 3060, 330, 46644, 1, 477, 330, 42562, 1082, 3343, 1472, 2011, 471, 264, 1160, 315, 5811, 3777, 4595, 304, 2768, 4823, 3645, 25, 5324, 8739, 9962, 794, 510, 8739, 1857, 320, 496, 705, 3777, 1857, 320, 496, 705, 61453, 3777, 1857, 320, 496, 7400, 633, 14711, 5810, 374, 279, 8278, 1495, 25, 220, 11579, 43035, 15419, 449, 293, 950, 332, 66796, 11, 264, 2536, 3751, 71916, 7294, 438, 26252, 11, 574, 7863, 449, 2211, 55681, 11, 3060, 34933, 477, 6593, 11, 304, 6978, 449, 83920, 22891, 423, 17, 47447, 9572, 13, 763, 459, 1825, 11, 47341, 11, 92520, 1992, 9269, 11, 6978, 1051, 47341, 311, 6514, 449, 220, 1135, 14060, 293, 950, 332, 66796, 320, 77, 284, 220, 14052, 8, 3131, 7446, 477, 311, 2211, 55681, 320, 77, 284, 220, 14052, 705, 3060, 477, 14946, 72783, 477, 45719, 26127, 315, 342, 24332, 33830, 65802, 349, 1475, 220, 1591, 2919, 13, 26150, 41265, 37442, 1051, 3115, 311, 6514, 8060, 323, 16945, 8624, 33824, 323, 20237, 13, 82935, 1392, 5343, 3477, 315, 66303, 68370, 2315, 11, 47447, 15696, 11, 18516, 86805, 77854, 2508, 5856, 5178, 2704, 11, 6784, 11, 3260, 4282, 292, 8670, 11, 323, 4367, 315, 2324, 14847, 13, 578, 23369, 8250, 315, 15419, 574, 220, 2137, 5672, 369, 293, 950, 332, 66796, 88186, 6978, 323, 220, 2983, 5672, 369, 2211, 496, 660, 6978, 26, 6514, 8060, 10222, 304, 220, 4331, 4, 323, 220, 2983, 4, 323, 8624, 33824, 304, 220, 3391, 4, 323, 220, 1644, 13689, 15947, 16134, 1741, 29, 31969, 6372, 46603, 2211, 55681, 369, 2225, 37442, 320, 47, 366, 477, 284, 220, 15, 13, 6726, 705, 449, 31397, 42338, 320, 65, 950, 332, 66796, 25, 936, 55681, 8, 315, 220, 16, 13, 4370, 320, 2721, 4, 12410, 10074, 510, 11487, 1145, 220, 16, 13, 972, 311, 220, 17, 13, 410, 8, 369, 892, 311, 6514, 8060, 323, 220, 16, 13, 21, 320, 2721, 4, 21351, 11, 220, 16, 13, 777, 311, 220, 17, 13, 868, 8, 369, 892, 311, 8624, 33824, 13, 694, 1741, 1822, 1741, 29, 5659, 279, 220, 16, 4771, 20237, 6492, 11, 279, 31397, 11595, 369, 19463, 315, 4648, 574, 220, 16, 13, 1682, 320, 2721, 4, 21351, 11, 220, 15, 13, 4161, 311, 220, 16, 13, 5332, 570, 694, 1741, 1822, 1741, 29, 14636, 3117, 11, 449, 264, 23369, 1833, 5352, 315, 220, 4218, 5672, 11, 23369, 20237, 706, 539, 1027, 8813, 304, 3060, 1912, 13, 694, 1741, 1822, 1741, 29, 29240, 505, 26954, 304, 3892, 4367, 315, 2324, 7482, 1051, 12207, 2204, 320, 47, 366, 477, 284, 220, 15, 13, 1721, 8, 1990, 6514, 5315, 48582, 505, 4038, 220, 16, 311, 220, 21, 11, 323, 682, 46603, 293, 950, 332, 66796, 13, 694, 1741, 1822, 1741, 29, 28993, 11, 279, 7294, 438, 26252, 574, 1664, 66441, 7863, 449, 2211, 55681, 26, 694, 1741, 1822, 1741, 29, 449, 293, 950, 332, 66796, 11, 4106, 18698, 288, 10222, 2753, 3629, 323, 17659, 8541, 29668, 323, 342, 1910, 66274, 561, 689, 810, 3629, 13, 694, 1741, 1822, 1741, 29, 10541, 264, 47040, 315, 220, 1135, 14060, 315, 293, 950, 332, 66796, 3131, 7446, 574, 539, 439, 7524, 439, 2211, 55681, 11, 694, 1741, 1822, 1741, 29, 279, 37849, 4367, 315, 2324, 20124, 323, 279, 3428, 39775, 315, 2536, 71, 494, 25180, 31959, 4455, 3493, 8125, 311, 15806, 293, 950, 332, 66796, 11, 439, 264, 3254, 37471, 8479, 11, 520, 5190, 35130, 13, 694, 1741, 29, 128009, 128006, 78191, 128007, 271, 5018, 8739, 9962, 794, 4482, 42562, 1082, 498, 330, 42562, 1082, 498, 330, 42562, 1082, 498, 330, 42562, 1082, 498, 330, 42562, 1082, 498, 330, 42562, 1082, 498, 330, 42562, 1082, 498, 330, 46644, 93546, 128009]\n",
      "inputs:\n",
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "### You are an expert in medical analysis. You are given the abstract of a random controlled trial which contains numbered argument components enclosed by <AC></AC> tags. Your task is to classify each argument components in the essay as either \"Claim\" or \"Premise\". You must return a list of argument component types in following JSON format: {\"component_types\": [component_type (str), component_type (str),..., component_type (str)]}\n",
      "\n",
      "### Here is the abstract text:  Single-agent therapy with bicalutamide, a nonsteroidal antiandrogen, was compared with castration, either surgical or medical, in patients with untreated Stage D2 prostate cancer. In an open, randomized, multicenter trial, patients were randomized to treatment with 50 mg bicalutamide (n = 243) once daily or to castration (n = 243), either orchiectomy or depot injection of goserelin acetate every 28 days. Primary efficacy endpoints were times to treatment failure and objective disease progression and survival. Assessments included review of measurable metastases, prostate dimensions, Eastern Cooperative Oncology Group performance status, pain, analgesic requirements, and quality of life responses. The median duration of therapy was 39 weeks for bicalutamide-treated patients and 42 weeks for castrated patients; treatment failure occurred in 53% and 42% and disease progression in 43% and 33%, respectively.<AC> Treatment effects favored castration for both endpoints (P < or = 0.002), with hazard ratios (bicalutamide:castration) of 1.54 (95% confidence interval [CI], 1.18 to 2.00) for time to treatment failure and 1.6 (95% CI, 1.19 to 2.15) for time to disease progression. </AC><AC> From the 1-year survival analysis, the hazard ratio for probability of death was 1.29 (95% CI, 0.96 to 1.72). </AC><AC> Thus far, with a median follow-up of 86 weeks, median survival has not been reached in either group. </AC><AC> Changes from baseline in several quality of life variables were significantly different (P < or = 0.01) between treatment groups periodically from months 1 to 6, and all favored bicalutamide. </AC><AC> Overall, the antiandrogen was well tolerated compared with castration; </AC><AC> with bicalutamide, hot flushes occurred less often and breast tenderness and gynecomastia more often. </AC><AC> Although a dosage of 50 mg of bicalutamide once daily was not as effective as castration, </AC><AC> the favorable quality of life outcomes and the low incidence of nonhormonal adverse events provide reasons to evaluate bicalutamide, as a single therapeutic agent, at higher doses. </AC><|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\"component_types\": [\"Premise\", \"Premise\", \"Premise\", \"Premise\", \"Premise\", \"Premise\", \"Premise\", \"Claim\"]}<|eot_id|>\n",
      "label_ids:\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 5018, 8739, 9962, 794, 4482, 42562, 1082, 498, 330, 42562, 1082, 498, 330, 42562, 1082, 498, 330, 42562, 1082, 498, 330, 42562, 1082, 498, 330, 42562, 1082, 498, 330, 42562, 1082, 498, 330, 46644, 93546, 128009]\n",
      "labels:\n",
      "{\"component_types\": [\"Premise\", \"Premise\", \"Premise\", \"Premise\", \"Premise\", \"Premise\", \"Premise\", \"Claim\"]}<|eot_id|>\n",
      "[INFO|configuration_utils.py:733] 2024-07-06 17:27:05,727 >> loading configuration file config.json from cache at /nfs/scratch/umushtaq/am_work/AbstRCT_FT/model_downloads/models--meta-llama--Meta-Llama-3-70B-Instruct/snapshots/7129260dd854a80eb10ace5f61c20324b472b31c/config.json\n",
      "[INFO|configuration_utils.py:800] 2024-07-06 17:27:05,727 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"meta-llama/Meta-Llama-3-70B-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 8192,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 28672,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 64,\n",
      "  \"num_hidden_layers\": 80,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.42.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "07/06/2024 17:27:05 - INFO - llamafactory.model.model_utils.quantization - Quantizing model to 4 bit with bitsandbytes.\n",
      "[INFO|modeling_utils.py:3556] 2024-07-06 17:27:05,817 >> loading weights file model.safetensors from cache at /nfs/scratch/umushtaq/am_work/AbstRCT_FT/model_downloads/models--meta-llama--Meta-Llama-3-70B-Instruct/snapshots/7129260dd854a80eb10ace5f61c20324b472b31c/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1531] 2024-07-06 17:27:05,837 >> Instantiating LlamaForCausalLM model under default dtype torch.float16.\n",
      "[INFO|configuration_utils.py:1000] 2024-07-06 17:27:05,837 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009\n",
      "}\n",
      "\n",
      "07/06/2024 17:27:05 - INFO - llamafactory.model.model_utils.quantization - Quantizing model to 4 bit with bitsandbytes.\n",
      "Loading checkpoint shards: 100%|████████████████| 30/30 [04:39<00:00,  9.33s/it]\n",
      "Loading checkpoint shards: 100%|████████████████| 30/30 [04:40<00:00,  9.33s/it]\n",
      "[INFO|modeling_utils.py:4364] 2024-07-06 17:31:47,184 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4372] 2024-07-06 17:31:47,185 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at meta-llama/Meta-Llama-3-70B-Instruct.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:955] 2024-07-06 17:31:47,403 >> loading configuration file generation_config.json from cache at /nfs/scratch/umushtaq/am_work/AbstRCT_FT/model_downloads/models--meta-llama--Meta-Llama-3-70B-Instruct/snapshots/7129260dd854a80eb10ace5f61c20324b472b31c/generation_config.json\n",
      "[INFO|configuration_utils.py:1000] 2024-07-06 17:31:47,404 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128009\n",
      "  ],\n",
      "  \"max_length\": 4096,\n",
      "  \"temperature\": 0.6,\n",
      "  \"top_p\": 0.9\n",
      "}\n",
      "\n",
      "07/06/2024 17:31:47 - INFO - llamafactory.model.model_utils.checkpointing - Gradient checkpointing enabled.\n",
      "07/06/2024 17:31:47 - INFO - llamafactory.model.model_utils.attention - Using torch SDPA for faster training and inference.\n",
      "07/06/2024 17:31:47 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n",
      "07/06/2024 17:31:47 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n",
      "07/06/2024 17:31:47 - INFO - llamafactory.model.model_utils.misc - Found linear modules: gate_proj,down_proj,o_proj,v_proj,up_proj,k_proj,q_proj\n",
      "07/06/2024 17:31:47 - INFO - llamafactory.model.model_utils.checkpointing - Gradient checkpointing enabled.\n",
      "07/06/2024 17:31:47 - INFO - llamafactory.model.model_utils.attention - Using torch SDPA for faster training and inference.\n",
      "07/06/2024 17:31:47 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n",
      "07/06/2024 17:31:47 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n",
      "07/06/2024 17:31:47 - INFO - llamafactory.model.model_utils.misc - Found linear modules: q_proj,down_proj,up_proj,k_proj,v_proj,gate_proj,o_proj\n",
      "07/06/2024 17:31:49 - INFO - llamafactory.model.loader - trainable params: 103,546,880 || all params: 70,657,253,376 || trainable%: 0.1465\n",
      "07/06/2024 17:31:49 - INFO - llamafactory.model.loader - trainable params: 103,546,880 || all params: 70,657,253,376 || trainable%: 0.1465\n",
      "[INFO|trainer.py:642] 2024-07-06 17:31:49,667 >> Using auto half precision backend\n",
      "07/06/2024 17:31:49 - WARNING - llamafactory.train.callbacks - Previous trainer log in this folder will be deleted.\n",
      "07/06/2024 17:31:50 - INFO - llamafactory.train.trainer_utils - Using LoRA+ optimizer with loraplus lr ratio 16.00.\n",
      "07/06/2024 17:31:50 - INFO - llamafactory.train.trainer_utils - Using LoRA+ optimizer with loraplus lr ratio 16.00.\n",
      "[INFO|trainer.py:2128] 2024-07-06 17:31:50,548 >> ***** Running training *****\n",
      "[INFO|trainer.py:2129] 2024-07-06 17:31:50,548 >>   Num examples = 350\n",
      "[INFO|trainer.py:2130] 2024-07-06 17:31:50,548 >>   Num Epochs = 10\n",
      "[INFO|trainer.py:2131] 2024-07-06 17:31:50,548 >>   Instantaneous batch size per device = 2\n",
      "[INFO|trainer.py:2134] 2024-07-06 17:31:50,548 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "[INFO|trainer.py:2135] 2024-07-06 17:31:50,548 >>   Gradient Accumulation steps = 4\n",
      "[INFO|trainer.py:2136] 2024-07-06 17:31:50,548 >>   Total optimization steps = 220\n",
      "[INFO|trainer.py:2137] 2024-07-06 17:31:50,556 >>   Number of trainable parameters = 103,546,880\n",
      "{'loss': 0.907, 'grad_norm': 1.2612724304199219, 'learning_rate': 1.1363636363636365e-05, 'epoch': 0.45}\n",
      "{'loss': 0.1257, 'grad_norm': 0.31300148367881775, 'learning_rate': 3.409090909090909e-05, 'epoch': 0.91}\n",
      "{'loss': 0.0567, 'grad_norm': 0.2611684799194336, 'learning_rate': 4.99716834795752e-05, 'epoch': 1.36}\n",
      "{'loss': 0.0371, 'grad_norm': 0.770071804523468, 'learning_rate': 4.947006115536947e-05, 'epoch': 1.82}\n",
      "{'loss': 0.0362, 'grad_norm': 0.3249063193798065, 'learning_rate': 4.835369650662767e-05, 'epoch': 2.27}\n",
      "{'loss': 0.0305, 'grad_norm': 0.36760589480400085, 'learning_rate': 4.665063509461097e-05, 'epoch': 2.73}\n",
      "{'loss': 0.0241, 'grad_norm': 0.12037166208028793, 'learning_rate': 4.440366160729392e-05, 'epoch': 3.18}\n",
      "{'loss': 0.0221, 'grad_norm': 0.16608065366744995, 'learning_rate': 4.166922501290729e-05, 'epoch': 3.64}\n",
      "{'loss': 0.0167, 'grad_norm': 0.07949560880661011, 'learning_rate': 3.851602043638994e-05, 'epoch': 4.09}\n",
      "{'loss': 0.0106, 'grad_norm': 0.1826515942811966, 'learning_rate': 3.502326338516534e-05, 'epoch': 4.55}\n",
      "{'loss': 0.0122, 'grad_norm': 0.6198115944862366, 'learning_rate': 3.127869967952698e-05, 'epoch': 5.0}\n",
      "{'loss': 0.007, 'grad_norm': 0.5121344327926636, 'learning_rate': 2.7376401082604564e-05, 'epoch': 5.45}\n",
      "{'loss': 0.0079, 'grad_norm': 0.0854296162724495, 'learning_rate': 2.3414402008585888e-05, 'epoch': 5.91}\n",
      "{'loss': 0.0048, 'grad_norm': 0.010135510936379433, 'learning_rate': 1.9492236680336485e-05, 'epoch': 6.36}\n",
      "{'loss': 0.003, 'grad_norm': 0.004002390895038843, 'learning_rate': 1.5708438608491814e-05, 'epoch': 6.82}\n",
      "{'loss': 0.003, 'grad_norm': 0.012202264741063118, 'learning_rate': 1.2158065210664848e-05, 'epoch': 7.27}\n",
      "{'loss': 0.0022, 'grad_norm': 0.11057227104902267, 'learning_rate': 8.930309757836517e-06, 'epoch': 7.73}\n",
      "{'loss': 0.0005, 'grad_norm': 0.0044962577521800995, 'learning_rate': 6.106260641143546e-06, 'epoch': 8.18}\n",
      "{'loss': 0.0007, 'grad_norm': 0.002590784104540944, 'learning_rate': 3.756864251262143e-06, 'epoch': 8.64}\n",
      "{'loss': 0.0004, 'grad_norm': 0.011587846092879772, 'learning_rate': 1.9411426473854688e-06, 'epoch': 9.09}\n",
      "{'loss': 0.0006, 'grad_norm': 0.07067341357469559, 'learning_rate': 7.047107919114588e-07, 'epoch': 9.55}\n",
      "{'loss': 0.0002, 'grad_norm': 0.004352538846433163, 'learning_rate': 7.863060120144317e-08, 'epoch': 10.0}\n",
      "100%|█████████████████████████████████████████| 220/220 [49:50<00:00, 13.22s/it][INFO|trainer.py:3478] 2024-07-06 18:21:40,902 >> Saving model checkpoint to /nfs/scratch/umushtaq/am_work/AbstRCT_FT/models/abstRCT_ATC_Meta-Llama-3-70B-Instruct/checkpoint-220\n",
      "\n",
      "config.json: 100%|█████████████████████████████| 654/654 [00:00<00:00, 7.37MB/s]\u001b[A\n",
      "[INFO|configuration_utils.py:733] 2024-07-06 18:21:41,429 >> loading configuration file config.json from cache at /home/umushtaq/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3-70B-Instruct/snapshots/7129260dd854a80eb10ace5f61c20324b472b31c/config.json\n",
      "[INFO|configuration_utils.py:800] 2024-07-06 18:21:41,429 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 8192,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 28672,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 64,\n",
      "  \"num_hidden_layers\": 80,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.42.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2574] 2024-07-06 18:21:42,196 >> tokenizer config file saved in /nfs/scratch/umushtaq/am_work/AbstRCT_FT/models/abstRCT_ATC_Meta-Llama-3-70B-Instruct/checkpoint-220/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2583] 2024-07-06 18:21:42,197 >> Special tokens file saved in /nfs/scratch/umushtaq/am_work/AbstRCT_FT/models/abstRCT_ATC_Meta-Llama-3-70B-Instruct/checkpoint-220/special_tokens_map.json\n",
      "[INFO|trainer.py:2383] 2024-07-06 18:21:44,297 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 2993.7417, 'train_samples_per_second': 1.169, 'train_steps_per_second': 0.073, 'train_loss': 0.05950795780465176, 'epoch': 10.0}\n",
      "100%|█████████████████████████████████████████| 220/220 [49:53<00:00, 13.61s/it]\n",
      "[INFO|trainer.py:3478] 2024-07-06 18:21:44,300 >> Saving model checkpoint to /nfs/scratch/umushtaq/am_work/AbstRCT_FT/models/abstRCT_ATC_Meta-Llama-3-70B-Instruct\n",
      "[INFO|configuration_utils.py:733] 2024-07-06 18:21:44,646 >> loading configuration file config.json from cache at /home/umushtaq/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3-70B-Instruct/snapshots/7129260dd854a80eb10ace5f61c20324b472b31c/config.json\n",
      "[INFO|configuration_utils.py:800] 2024-07-06 18:21:44,647 >> Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 8192,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 28672,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 64,\n",
      "  \"num_hidden_layers\": 80,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.42.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2574] 2024-07-06 18:21:45,283 >> tokenizer config file saved in /nfs/scratch/umushtaq/am_work/AbstRCT_FT/models/abstRCT_ATC_Meta-Llama-3-70B-Instruct/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2583] 2024-07-06 18:21:45,284 >> Special tokens file saved in /nfs/scratch/umushtaq/am_work/AbstRCT_FT/models/abstRCT_ATC_Meta-Llama-3-70B-Instruct/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        10.0\n",
      "  total_flos               = 913507704GF\n",
      "  train_loss               =      0.0595\n",
      "  train_runtime            =  0:49:53.74\n",
      "  train_samples_per_second =       1.169\n",
      "  train_steps_per_second   =       0.073\n",
      "[INFO|modelcard.py:449] 2024-07-06 18:21:45,439 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n"
     ]
    }
   ],
   "source": [
    "!llamafactory-cli train $train_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVNaC-xS5N40"
   },
   "source": [
    "## Inference on the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/scratch/umushtaq/am_work/AbstRCT_FT/models/abstRCT_ATC_Meta-Llama-3-70B-Instruct'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trainer_log.jsonl',\n",
       " 'checkpoint-220',\n",
       " 'README.md',\n",
       " 'adapter_model.safetensors',\n",
       " 'adapter_config.json',\n",
       " 'tokenizer_config.json',\n",
       " 'special_tokens_map.json',\n",
       " 'tokenizer.json',\n",
       " 'training_args.bin',\n",
       " 'train_results.json',\n",
       " 'all_results.json',\n",
       " 'trainer_state.json']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "oh8H9A_25SF9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %cd /content/LLaMA-Factory/\n",
    "\n",
    "args = dict(\n",
    "  model_name_or_path=base_model, # use bnb-4bit-quantized Llama-3-8B-Instruct model\n",
    "  adapter_name_or_path=output_dir,            # load the saved LoRA adapters\n",
    "  cache_dir=model_downloads,\n",
    "  template=\"llama3\",                     # same to the one in training\n",
    "  finetuning_type=\"lora\",                  # same to the one in training\n",
    "  quantization_bit=4,                    # load 4-bit quantized model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:2161] 2024-07-06 18:45:35,338 >> loading file tokenizer.json from cache at /nfs/scratch/umushtaq/am_work/AbstRCT_FT/model_downloads/models--meta-llama--Meta-Llama-3-70B-Instruct/snapshots/7129260dd854a80eb10ace5f61c20324b472b31c/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2161] 2024-07-06 18:45:35,340 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2161] 2024-07-06 18:45:35,341 >> loading file special_tokens_map.json from cache at /nfs/scratch/umushtaq/am_work/AbstRCT_FT/model_downloads/models--meta-llama--Meta-Llama-3-70B-Instruct/snapshots/7129260dd854a80eb10ace5f61c20324b472b31c/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2161] 2024-07-06 18:45:35,341 >> loading file tokenizer_config.json from cache at /nfs/scratch/umushtaq/am_work/AbstRCT_FT/model_downloads/models--meta-llama--Meta-Llama-3-70B-Instruct/snapshots/7129260dd854a80eb10ace5f61c20324b472b31c/tokenizer_config.json\n",
      "[WARNING|logging.py:313] 2024-07-06 18:45:35,703 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/06/2024 18:45:35 - INFO - llamafactory.data.template - Replace eos token: <|eot_id|>\n",
      "07/06/2024 18:45:35 - INFO - llamafactory.data.template - Add pad token: <|eot_id|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:733] 2024-07-06 18:45:35,853 >> loading configuration file config.json from cache at /nfs/scratch/umushtaq/am_work/AbstRCT_FT/model_downloads/models--meta-llama--Meta-Llama-3-70B-Instruct/snapshots/7129260dd854a80eb10ace5f61c20324b472b31c/config.json\n",
      "[INFO|configuration_utils.py:800] 2024-07-06 18:45:35,863 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"meta-llama/Meta-Llama-3-70B-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 8192,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 28672,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 64,\n",
      "  \"num_hidden_layers\": 80,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.42.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/06/2024 18:45:35 - INFO - llamafactory.model.model_utils.quantization - Quantizing model to 4 bit with bitsandbytes.\n",
      "07/06/2024 18:45:35 - INFO - llamafactory.model.patcher - Using KV cache for faster generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:3556] 2024-07-06 18:45:36,134 >> loading weights file model.safetensors from cache at /nfs/scratch/umushtaq/am_work/AbstRCT_FT/model_downloads/models--meta-llama--Meta-Llama-3-70B-Instruct/snapshots/7129260dd854a80eb10ace5f61c20324b472b31c/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1531] 2024-07-06 18:45:36,159 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:1000] 2024-07-06 18:45:36,195 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f1a391d52c49f795e3aae05429e64a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:4364] 2024-07-06 18:49:04,696 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4372] 2024-07-06 18:49:04,698 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at meta-llama/Meta-Llama-3-70B-Instruct.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:955] 2024-07-06 18:49:04,898 >> loading configuration file generation_config.json from cache at /nfs/scratch/umushtaq/am_work/AbstRCT_FT/model_downloads/models--meta-llama--Meta-Llama-3-70B-Instruct/snapshots/7129260dd854a80eb10ace5f61c20324b472b31c/generation_config.json\n",
      "[INFO|configuration_utils.py:1000] 2024-07-06 18:49:04,899 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128009\n",
      "  ],\n",
      "  \"max_length\": 4096,\n",
      "  \"temperature\": 0.6,\n",
      "  \"top_p\": 0.9\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/06/2024 18:49:05 - INFO - llamafactory.model.model_utils.attention - Using torch SDPA for faster training and inference.\n",
      "07/06/2024 18:49:06 - INFO - llamafactory.model.adapter - Loaded adapter(s): /nfs/scratch/umushtaq/am_work/AbstRCT_FT/models/abstRCT_ATC_Meta-Llama-3-70B-Instruct\n",
      "07/06/2024 18:49:06 - INFO - llamafactory.model.loader - all params: 70,657,253,376\n"
     ]
    }
   ],
   "source": [
    "model = ChatModel(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neo, gla, mix test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_name = \"abstRCT_ATC_test_mix.json\"\n",
    "test_dataset_file = os.path.join(dataset_dir, test_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_suffix = test_dataset_name.split(\"_\")[3].replace(\".json\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(test_dataset_file, \"r+\") as fh:\n",
    "    test_dataset = json.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_prompts = []\n",
    "test_grounds = []\n",
    "\n",
    "for sample in test_dataset:\n",
    "    test_prompts.append(\"\\nUser:\" + sample[\"instruction\"] + sample[\"input\"])\n",
    "    test_grounds.append(sample[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e587ce4b4f3d478daf28aef8a17c56a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_predictions = []\n",
    "\n",
    "for prompt in tqdm(test_prompts):\n",
    "\n",
    "    messages = []\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    response = \"\"\n",
    "    \n",
    "    for new_text in model.stream_chat(messages):\n",
    "        #print(new_text, end=\"\", flush=True)\n",
    "        response += new_text\n",
    "        #print()\n",
    "    test_predictions.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "    torch_gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# next(model.engine.model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(output_dir, f\"\"\"abstRCT_ATC_results_{test_file_suffix}{nb_epochs}.pickle\"\"\"), 'wb') as fh:\n",
    "    results_d = {\"ground_truths\": test_grounds,\n",
    "                 \"predictions\": test_predictions    \n",
    "        \n",
    "    }\n",
    "    pickle.dump(results_d, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-processing (New)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opposite(component_type):\n",
    "\n",
    "    if component_type == \"Premise\":\n",
    "        return \"Claim\"\n",
    "    elif component_type == \"Claim\":\n",
    "        return \"Premise\"\n",
    "    elif component_type == \"MajorClaim\":\n",
    "        return \"Claim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonize_preds(grounds, preds):\n",
    "\n",
    "    l1, l2 = len(preds), len(grounds)\n",
    "    if l1 < l2:\n",
    "        diff = l2 - l1\n",
    "        preds = preds + [opposite(x) for x in grounds[l1:]]\n",
    "    else:\n",
    "        preds = preds[:l2]\n",
    "        \n",
    "    return preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(results):\n",
    "\n",
    "    grounds = results[\"ground_truths\"]\n",
    "    preds = results[\"predictions\"]\n",
    "    \n",
    "    grounds = [json.loads(x)[\"component_types\"] for x in grounds]\n",
    "    preds = [x[\"content\"] for x in preds]\n",
    "    preds = [json.loads(x)[\"component_types\"] for x in preds]\n",
    "\n",
    "    for i,(x,y) in enumerate(zip(grounds, preds)):\n",
    "    \n",
    "        if len(x) != len(y):\n",
    "        \n",
    "            preds[i] = harmonize_preds(x, y)\n",
    "\n",
    "    ATC_preds = [item for row in preds for item in row]\n",
    "    ATC_grounds = [item for row in grounds for item in row]\n",
    "\n",
    "    print(classification_report(ATC_grounds, ATC_preds, digits=3))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(output_dir, f\"\"\"abstRCT_ATC_results_mix{nb_epochs}.pickle\"\"\"), \"rb\") as fh:\n",
    "        \n",
    "        results = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Claim      0.920     0.925     0.922       212\n",
      "     Premise      0.960     0.957     0.958       397\n",
      "\n",
      "    accuracy                          0.946       609\n",
      "   macro avg      0.940     0.941     0.940       609\n",
      "weighted avg      0.946     0.946     0.946       609\n",
      "\n"
     ]
    }
   ],
   "source": [
    "post_process(results)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Results for 70B Instruct\n",
    "\n",
    "neo_test\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "       Claim      0.925     0.891     0.908       248\n",
    "     Premise      0.940     0.959     0.950       443\n",
    "\n",
    "    accuracy                          0.935       691\n",
    "   macro avg      0.932     0.925     0.929       691\n",
    "weighted avg      0.935     0.935     0.935       691\n",
    "\n",
    "gla_test\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "       Claim      0.880     0.880     0.880       191\n",
    "     Premise      0.946     0.946     0.946       424\n",
    "\n",
    "    accuracy                          0.925       615\n",
    "   macro avg      0.913     0.913     0.913       615\n",
    "weighted avg      0.925     0.925     0.925       615\n",
    "\n",
    "\n",
    "mix_test\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "       Claim      0.920     0.925     0.922       212\n",
    "     Premise      0.960     0.957     0.958       397\n",
    "\n",
    "    accuracy                          0.946       609\n",
    "   macro avg      0.940     0.941     0.940       609\n",
    "weighted avg      0.946     0.946     0.946       609"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Results for 70B Instruct 4bit\n",
    "\n",
    "neo_test\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "       Claim      0.919     0.875     0.897       248\n",
    "     Premise      0.932     0.957     0.944       443\n",
    "\n",
    "    accuracy                          0.928       691\n",
    "   macro avg      0.926     0.916     0.921       691\n",
    "weighted avg      0.927     0.928     0.927       691\n",
    "\n",
    "\n",
    "gla_test\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "       Claim      0.882     0.864     0.873       191\n",
    "     Premise      0.939     0.948     0.944       424\n",
    "\n",
    "    accuracy                          0.922       615\n",
    "   macro avg      0.911     0.906     0.908       615\n",
    "weighted avg      0.922     0.922     0.922       615\n",
    "\n",
    "mix_test\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "       Claim      0.947     0.925     0.936       212\n",
    "     Premise      0.960     0.972     0.966       397\n",
    "\n",
    "    accuracy                          0.956       609\n",
    "   macro avg      0.954     0.948     0.951       609\n",
    "weighted avg      0.956     0.956     0.956       609"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Results for 8B Instruct 4bit\n",
    "\n",
    "neo_test\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "       Claim      0.944     0.887     0.915       248\n",
    "     Premise      0.939     0.971     0.954       443\n",
    "\n",
    "    accuracy                          0.941       691\n",
    "   macro avg      0.942     0.929     0.935       691\n",
    "weighted avg      0.941     0.941     0.940       691\n",
    "\n",
    "gla_test\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "       Claim      0.887     0.864     0.875       191\n",
    "     Premise      0.939     0.950     0.945       424\n",
    "\n",
    "    accuracy                          0.924       615\n",
    "   macro avg      0.913     0.907     0.910       615\n",
    "weighted avg      0.923     0.924     0.923       615\n",
    "\n",
    "mix_test\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "       Claim      0.939     0.939     0.939       212\n",
    "     Premise      0.967     0.967     0.967       397\n",
    "\n",
    "    accuracy                          0.957       609\n",
    "   macro avg      0.953     0.953     0.953       609\n",
    "weighted avg      0.957     0.957     0.957       609"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Results for 8B Instruct\n",
    "neo_test\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "       Claim      0.916     0.875     0.895       248\n",
    "     Premise      0.932     0.955     0.943       443\n",
    "\n",
    "    accuracy                          0.926       691\n",
    "   macro avg      0.924     0.915     0.919       691\n",
    "weighted avg      0.926     0.926     0.926       691\n",
    "\n",
    "gla_test\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "       Claim      0.882     0.864     0.873       191\n",
    "     Premise      0.939     0.948     0.944       424\n",
    "\n",
    "    accuracy                          0.922       615\n",
    "   macro avg      0.911     0.906     0.908       615\n",
    "weighted avg      0.922     0.922     0.922       615\n",
    "\n",
    "mix_test\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "       Claim      0.916     0.925     0.920       212\n",
    "     Premise      0.959     0.955     0.957       397\n",
    "\n",
    "    accuracy                          0.944       609\n",
    "   macro avg      0.938     0.940     0.939       609\n",
    "weighted avg      0.944     0.944     0.944       609\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import json\n",
    "# import ast\n",
    "# from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'/Utilisateurs/umushtaq/models/PE_ATC_llama-3-8b-Instruct-bnb-4bit'\n",
    "# output_dir = 'models/PE_ATC_essay_llama-3-8b-Instruct-bnb-4bit'\n",
    "# nb_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(output_dir, f\"\"\"abstRCT_ATC_results_{nb_epochs}.pickle\"\"\"), \"rb\") as fh:\n",
    "        \n",
    "        results = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grounds = results[\"ground_truths\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = results[\"predictions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounds = [json.loads(x)[\"component_types\"] for x in grounds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [x[\"content\"] for x in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [json.loads(x)[\"component_types\"] for x in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opposite(component_type):\n",
    "\n",
    "    if component_type == \"Premise\":\n",
    "        return \"Claim\"\n",
    "    elif component_type == \"Claim\":\n",
    "        return \"Premise\"\n",
    "    elif component_type == \"MajorClaim\":\n",
    "        return \"Claim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonize_preds(grounds, preds):\n",
    "\n",
    "    l1, l2 = len(preds), len(grounds)\n",
    "    if l1 < l2:\n",
    "        diff = l2 - l1\n",
    "        preds = preds + [opposite(x) for x in grounds[l1:]]\n",
    "    else:\n",
    "        preds = preds[:l2]\n",
    "        \n",
    "    return preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(x,y) in enumerate(zip(grounds, preds)):\n",
    "    \n",
    "    if len(x) != len(y):\n",
    "        \n",
    "        preds[i] = harmonize_preds(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATC_preds = [item for row in preds for item in row]\n",
    "ATC_grounds = [item for row in grounds for item in row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check: \n",
    "len(ATC_preds) == len(ATC_grounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ATC_grounds, ATC_preds, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"\"\"{output_dir}/classification_report.pickle\"\"\", 'wb') as fh:\n",
    "    \n",
    "    pickle.dump(classification_report(ATC_grounds, ATC_preds, output_dict=True), fh)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
